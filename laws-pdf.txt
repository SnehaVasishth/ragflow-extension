[
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=561x1687 at 0x265D0264580>",
    "page_num_int": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "position_int": [
      [
        1,
        212,
        399,
        100,
        114
      ],
      [
        1,
        132,
        319,
        184,
        196
      ],
      [
        1,
        237,
        424,
        184,
        196
      ],
      [
        1,
        336,
        523,
        184,
        196
      ],
      [
        1,
        423,
        610,
        184,
        196
      ],
      [
        1,
        138,
        325,
        196,
        208
      ],
      [
        1,
        241,
        428,
        196,
        208
      ],
      [
        1,
        330,
        517,
        196,
        208
      ],
      [
        1,
        423,
        610,
        196,
        208
      ],
      [
        1,
        114,
        301,
        207,
        218
      ],
      [
        1,
        228,
        415,
        207,
        218
      ],
      [
        1,
        322,
        509,
        207,
        218
      ],
      [
        1,
        420,
        607,
        207,
        218
      ],
      [
        1,
        142,
        329,
        233,
        245
      ],
      [
        1,
        247,
        434,
        234,
        246
      ],
      [
        1,
        392,
        579,
        234,
        246
      ],
      [
        1,
        133,
        320,
        246,
        258
      ],
      [
        1,
        242,
        429,
        246,
        258
      ],
      [
        1,
        394,
        581,
        244,
        258
      ],
      [
        1,
        124,
        311,
        255,
        269
      ],
      [
        1,
        233,
        420,
        256,
        268
      ],
      [
        1,
        361,
        548,
        255,
        269
      ],
      [
        1,
        237,
        424,
        284,
        308
      ],
      [
        1,
        283,
        470,
        336,
        348
      ]
    ],
    "top_int": [
      100,
      184,
      184,
      184,
      184,
      196,
      196,
      196,
      196,
      207,
      207,
      207,
      207,
      233,
      234,
      234,
      246,
      246,
      244,
      255,
      256,
      255,
      284,
      336
    ],
    "content_with_weight": "Attention Is All You Need\nAshish Vaswani*\nNoam Shazeer*\nNiki Parmar*\nJakob Uszkoreit*\nGoogle Brain\nGoogle Brain\nGoogle Research\nGoogle Research\navaswani@google.com\nnoam@google.com\nnikip@google.com\nusz@google.com\nLlion Jones*\nAidan N. Gomez* â†‘\nLukasz Kaiser*\nGoogle Research\nUniversity of Toronto\nGoogle Brain\n1lion@google.com\naidan@cs.toronto.edu\nlukaszkaiser@google.com\nIllia Polosukhin* illia.polosukhin@gmail.com\nAbstract",
    "content_ltks": "attent is all you need ashish vaswani noam shazeer niki parmar jakob uszkoreit googl brain googl brain googl research googl research avaswani googl com noam googl com nikip googl com usz googl com llion jone aidan n gomez lukasz kaiser googl research univers of toronto googl brain 1lion googl com aidan c toronto edu lukaszkais googl com illia polosukhin illia polosukhin gmail com abstract",
    "content_sm_ltks": "attent is all you need ashish vaswani noam shazeer niki parmar jakob uszkoreit googl brain googl brain googl research googl research avaswani googl com noam googl com nikip googl com usz googl com llion jone aidan n gomez lukasz kaiser googl research univers of toronto googl brain 1lion googl com aidan c toronto edu lukaszkais googl com illia polosukhin illia polosukhin gmail com abstract"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=988x1197 at 0x265D02659F0>",
    "page_num_int": [
      1
    ],
    "position_int": [
      [
        1,
        141,
        470,
        361,
        526
      ]
    ],
    "top_int": [
      361
    ],
    "content_with_weight": "The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attentionmechanism. We propose a new simple network architecture, the Transformer,based solely on attention mechanisms, dispensing with recurrence and convolutionsentirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantlyless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, includingensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,our model establishes a new single-model state-of-the-art BLEU score of 41.8 aftertraining for 3.5 days on eight GPUs, a small fraction of the training costs of thebest models from the literature. We show that the Transformer generalizes well toother tasks by applying it successfully to English constituency parsing both withlarge and limited training data.",
    "content_ltks": "the domin sequenc transduct model are base on complex recurr orconvolut neural network that includ an encod and a decod the best perform model also connect the encod and decod through an attentionmechan we propos a new simpl network architectur the transform base sole on attent mechan dispens with recurr and convolutionsentir experi on two machin translat task show these model to be superior in qualiti while be more paralleliz and requir significantlyless time to train our model achiev 28 4 bleu on the wmt 2014 english to german translat task improv over the exist best result includingensembl by over 2 bleu on the wmt 2014 english to french translat task our model establish a new singl model state of the art bleu score of 41 8 aftertrain for 35 day on eight gpu a small fraction of the train cost of thebest model from the literatur we show that the transform gener well toother task by appli it success to english constitu pars both withlarg and limit train data",
    "content_sm_ltks": "the domin sequenc transduct model are base on complex recurr orconvolut neural network that includ an encod and a decod the best perform model also connect the encod and decod through an attentionmechan we propos a new simpl network architectur the transform base sole on attent mechan dispens with recurr and convolutionsentir experi on two machin translat task show these model to be superior in qualiti while be more paralleliz and requir significantlyless time to train our model achiev 28 4 bleu on the wmt 2014 english to german translat task improv over the exist best result includingensembl by over 2 bleu on the wmt 2014 english to french translat task our model establish a new singl model state of the art bleu score of 41 8 aftertrain for 35 day on eight gpu a small fraction of the train cost of thebest model from the literatur we show that the transform gener well toother task by appli it success to english constitu pars both withlarg and limit train data"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1202x1053 at 0x265D0265A50>",
    "page_num_int": [
      1,
      1,
      1,
      1
    ],
    "position_int": [
      [
        1,
        124,
        525,
        547,
        558
      ],
      [
        1,
        105,
        506,
        569,
        595
      ],
      [
        1,
        105,
        506,
        599,
        691
      ],
      [
        1,
        119,
        520,
        691,
        703
      ]
    ],
    "top_int": [
      547,
      569,
      599,
      691
    ],
    "content_with_weight": "Introduction\n Recurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks  in particular, have been firmly established as state of the art approaches in sequence modeling and\n*Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and startedthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models andhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product atention, multi-head attention and the parameter-free position representation and became the other person involved in nearly everydetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase andtensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, andefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of andimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively acceleratingour research.\nf Work performed while at Google Brain.",
    "content_ltks": "introduct recurr neural network long short term memori 13 and gate recurr 7 neural network in particular have been firmli establish a state of the art approach in sequenc model and equal contribut list order is random jakob propos replac rnn with self attent and startedth effort to evalu thi idea ashish with illia design and implement the first transform model andha been crucial involv in everi aspect of thi work noam propos scale dot product atent multi head attent and the paramet free posit represent and becam the other person involv in nearli everydetail niki design implement tune and evalu countless model variant in our origin codebas andtensor2tensor llion also experi with novel model variant wa respons for our initi codebas andeffici infer and visual lukasz and aidan spent countless long day design variou part of andimpl tensor2tensor replac our earlier codebas greatli improv result and massiv acceleratingour research f work perform while at googl brain",
    "content_sm_ltks": "introduct recurr neural network long short term memori 13 and gate recurr 7 neural network in particular have been firmli establish a state of the art approach in sequenc model and equal contribut list order is random jakob propos replac rnn with self attent and startedth effort to evalu thi idea ashish with illia design and implement the first transform model andha been crucial involv in everi aspect of thi work noam propos scale dot product atent multi head attent and the paramet free posit represent and becam the other person involv in nearli everydetail niki design implement tune and evalu countless model variant in our origin codebas andtensor2tensor llion also experi with novel model variant wa respons for our initi codebas andeffici infer and visual lukasz and aidan spent countless long day design variou part of andimpl tensor2tensor replac our earlier codebas greatli improv result and massiv acceleratingour research f work perform while at googl brain"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x1168 at 0x265D0264130>",
    "page_num_int": [
      1,
      1,
      2,
      2
    ],
    "position_int": [
      [
        1,
        116,
        516,
        698,
        715
      ],
      [
        1,
        107,
        507,
        732,
        743
      ],
      [
        2,
        106,
        506,
        73,
        107
      ],
      [
        2,
        105,
        505,
        112,
        200
      ]
    ],
    "top_int": [
      698,
      732,
      73,
      112
    ],
    "content_with_weight": "+Work performed while at Google Research.\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\ntransduction problems such as language modeling and machine translation [35, 2, 5]. Numerousefforts have since continued to push the boundaries of recurrent language models and encoder-decoderarchitectures [38, 24, 15].\nRecurrent models typically factor computation along the symbol positions of the input and outputsequences. Aligning the positions to steps in computation time, they generate a sequence of hiddenstates ht, as a function of the previous hidden state ht-1 and the input for position t. This inherentlysequential nature precludes parallelization within training examples, which becomes critical at longersequence lengths, as memory constraints limit batching across examples. Recent work has achievedsignificant improvements in computational efficiency through factorization tricks [21] and conditionalcomputation [32], while also improving model performance in case of the latter. The fundamentalconstraint of sequential computation, however, remains.",
    "content_ltks": "work perform while at googl research 31st confer on neural inform process system nip 2017 long beach ca usa transduct problem such a languag model and machin translat 352 5 numerouseffort have sinc continu to push the boundari of recurr languag model and encod decoderarchitectur 38 24 15 recurr model typic factor comput along the symbol posit of the input and outputsequ align the posit to step in comput time they gener a sequenc of hiddenst ht a a function of the previou hidden state ht 1 and the input for posit t thi inherentlysequenti natur preclud parallel within train exampl which becom critic at longersequ length a memori constraint limit batch across exampl recent work ha achievedsignific improv in comput effici through factor trick 21 and conditionalcomput 32 while also improv model perform in case of the latter the fundamentalconstraint of sequenti comput howev remain",
    "content_sm_ltks": "work perform while at googl research 31st confer on neural inform process system nip 2017 long beach ca usa transduct problem such a languag model and machin translat 352 5 numerouseffort have sinc continu to push the boundari of recurr languag model and encod decoderarchitectur 38 24 15 recurr model typic factor comput along the symbol posit of the input and outputsequ align the posit to step in comput time they gener a sequenc of hiddenst ht a a function of the previou hidden state ht 1 and the input for posit t thi inherentlysequenti natur preclud parallel within train exampl which becom critic at longersequ length a memori constraint limit batch across exampl recent work ha achievedsignific improv in comput effici through factor trick 21 and conditionalcomput 32 while also improv model perform in case of the latter the fundamentalconstraint of sequenti comput howev remain"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1198x1035 at 0x265D0265DB0>",
    "page_num_int": [
      2,
      2,
      2,
      2
    ],
    "position_int": [
      [
        2,
        106,
        505,
        203,
        249
      ],
      [
        2,
        107,
        506,
        254,
        277
      ],
      [
        2,
        107,
        506,
        276,
        298
      ],
      [
        2,
        105,
        504,
        317,
        331
      ]
    ],
    "top_int": [
      203,
      254,
      276,
      317
    ],
    "content_with_weight": "Attention mechanisms have become an integral part of compelling sequence modeling and transduc-tion models in various tasks, allowing modeling of dependencies without regard to their distance inthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanismsare used in conjunction with a recurrent network.\nIn this work we propose the Transformer, a model architecture eschewing recurrence and insteadrelying entirely on an attention mechanism to draw global dependencies between input and output.\nThe Transformer allows for significantly more parallelization and can reach a new state of the art intranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\n2Background",
    "content_ltks": "attent mechan have becom an integr part of compel sequenc model and transduc tion model in variou task allow model of depend without regard to their distanc inth input or output sequenc 2 19 in all but a few case 27 howev such attent mechanismsar use in conjunct with a recurr network in thi work we propos the transform a model architectur eschew recurr and insteadr entir on an attent mechan to draw global depend between input and output the transform allow for significantli more parallel and can reach a new state of the art intransl qualiti after be train for a littl a twelv hour on eight p100 gpu 2background",
    "content_sm_ltks": "attent mechan have becom an integr part of compel sequenc model and transduc tion model in variou task allow model of depend without regard to their distanc inth input or output sequenc 2 19 in all but a few case 27 howev such attent mechanismsar use in conjunct with a recurr network in thi work we propos the transform a model architectur eschew recurr and insteadr entir on an attent mechan to draw global depend between input and output the transform allow for significantli more parallel and can reach a new state of the art intransl qualiti after be train for a littl a twelv hour on eight p100 gpu 2background"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1198x998 at 0x265D0265FC0>",
    "page_num_int": [
      2
    ],
    "position_int": [
      [
        2,
        106,
        505,
        346,
        445
      ]
    ],
    "top_int": [
      346
    ],
    "content_with_weight": "The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic buildingblock, computing hidden representations in parallel for allinput and output positions. In these models,the number of operations required to relate signals from two arbitrary input or output positions growsin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makesit more difficult to learn dependencies between distant positions [12]. In the Transformer this isreduced to a constant number of operations, albeit at the cost of reduced effective resolution dueto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention asdescribed in section 3.2.",
    "content_ltks": "the goal of reduc sequenti comput also form the foundat of the extend neural gpu 16 bytenet 18 and convs2 9 all of which use convolut neural network a basic buildingblock comput hidden represent in parallel for allinput and output posit in these model the number of oper requir to relat signal from two arbitrari input or output posit growsin the distanc between posit linearli for convs2 and logarithm for bytenet thi makesit more difficult to learn depend between distant posit 12 in the transform thi isreduc to a constant number of oper albeit at the cost of reduc effect resolut dueto averag attent weight posit an effect we counteract with multi head attent asdescrib in section 32",
    "content_sm_ltks": "the goal of reduc sequenti comput also form the foundat of the extend neural gpu 16 bytenet 18 and convs2 9 all of which use convolut neural network a basic buildingblock comput hidden represent in parallel for allinput and output posit in these model the number of oper requir to relat signal from two arbitrari input or output posit growsin the distanc between posit linearli for convs2 and logarithm for bytenet thi makesit more difficult to learn depend between distant posit 12 in the transform thi isreduc to a constant number of oper albeit at the cost of reduc effect resolut dueto averag attent weight posit an effect we counteract with multi head attent asdescrib in section 32"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x1131 at 0x265D0265D50>",
    "page_num_int": [
      2,
      2,
      2,
      2
    ],
    "position_int": [
      [
        2,
        107,
        507,
        450,
        495
      ],
      [
        2,
        105,
        505,
        497,
        533
      ],
      [
        2,
        106,
        506,
        538,
        581
      ],
      [
        2,
        105,
        505,
        602,
        614
      ]
    ],
    "top_int": [
      450,
      497,
      538,
      602
    ],
    "content_with_weight": "Self-attention, sometimes called intra-attention is an attention mechanism relating different positionsof a single sequence in order to compute a representation of the sequence. Self-attention has beenused successfully in a variety of tasks including reading comprehension, abstractive summarization,textual entailment and learning task-independent sentence representations [4, 27, 28, 22].\n End-to-end memory networks are based on a recurrent attention mechanism instead of sequence- aligned recurrence and have been shown to perform well on simple-language question answering andlanguage modeling tasks [34].\nTo the best of our knowledge, however, the Transformer is the first transduction model relyingentirely on self-attention to compute representations of its input and output without using sequence-aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivateself-attention and discuss its advantages over models such as [17, 18] and [9].\n3Model Architecture",
    "content_ltks": "self attent sometim call intra attent is an attent mechan relat differ positionsof a singl sequenc in order to comput a represent of the sequenc self attent ha beenus success in a varieti of task includ read comprehens abstract summar textual entail and learn task independ sentenc represent 4 27 28 22 end to end memori network are base on a recurr attent mechan instead of sequenc align recurr and have been shown to perform well on simpl languag question answer andlanguag model task 34 to the best of our knowledg howev the transform is the first transduct model relyingentir on self attent to comput represent of it input and output without use sequenc align rnn or convolut in the follow section we will describ the transform motivateself attent and discu it advantag over model such a 1718 and 9 3model architectur",
    "content_sm_ltks": "self attent sometim call intra attent is an attent mechan relat differ positionsof a singl sequenc in order to comput a represent of the sequenc self attent ha beenus success in a varieti of task includ read comprehens abstract summar textual entail and learn task independ sentenc represent 4 27 28 22 end to end memori network are base on a recurr attent mechan instead of sequenc align recurr and have been shown to perform well on simpl languag question answer andlanguag model task 34 to the best of our knowledg howev the transform is the first transduct model relyingentir on self attent to comput represent of it input and output without use sequenc align rnn or convolut in the follow section we will describ the transform motivateself attent and discu it advantag over model such a 1718 and 9 3model architectur"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x2152 at 0x265D0265C60>",
    "page_num_int": [
      2,
      2,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3
    ],
    "position_int": [
      [
        2,
        105,
        505,
        630,
        687
      ],
      [
        2,
        106,
        506,
        690,
        725
      ],
      [
        3,
        320,
        720,
        70,
        111
      ],
      [
        3,
        316,
        716,
        147,
        199
      ],
      [
        3,
        241,
        641,
        198,
        207
      ],
      [
        3,
        322,
        722,
        202,
        213
      ],
      [
        3,
        254,
        654,
        212,
        221
      ],
      [
        3,
        327,
        727,
        213,
        222
      ],
      [
        3,
        250,
        650,
        221,
        230
      ],
      [
        3,
        393,
        793,
        222,
        231
      ],
      [
        3,
        317,
        717,
        243,
        252
      ],
      [
        3,
        201,
        601,
        248,
        258
      ],
      [
        3,
        240,
        640,
        252,
        260
      ],
      [
        3,
        328,
        728,
        256,
        265
      ],
      [
        3,
        245,
        645,
        264,
        274
      ],
      [
        3,
        323,
        723,
        263,
        274
      ],
      [
        3,
        249,
        649,
        273,
        284
      ],
      [
        3,
        328,
        728,
        274,
        283
      ],
      [
        3,
        195,
        595,
        310,
        319
      ],
      [
        3,
        377,
        777,
        312,
        321
      ],
      [
        3,
        195,
        595,
        320,
        329
      ],
      [
        3,
        376,
        776,
        320,
        331
      ],
      [
        3,
        257,
        657,
        335,
        345
      ],
      [
        3,
        330,
        730,
        335,
        345
      ],
      [
        3,
        243,
        643,
        343,
        352
      ],
      [
        3,
        322,
        722,
        341,
        353
      ],
      [
        3,
        252,
        652,
        373,
        384
      ],
      [
        3,
        318,
        718,
        373,
        393
      ]
    ],
    "top_int": [
      630,
      690,
      70,
      147,
      198,
      202,
      212,
      213,
      221,
      222,
      243,
      248,
      252,
      256,
      264,
      263,
      273,
      274,
      310,
      312,
      320,
      320,
      335,
      335,
      343,
      341,
      373,
      373
    ],
    "content_with_weight": "Most competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35]Here, the encoder maps an input sequence of symbol representations (1,., n) to a sequenceof continuous representations z = (z1, ., Zn). Given z, the decoder then generates an outputsequence (y1 ., ym) of symbols one element at a time. At each step the model is auto-regressive[10], consuming the previously generated symbols as additional input when generating the next.\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fullyconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,respectively.\nOutputProbabilitiesSoftmax\nAdd&NormFeedForwardAdd&Norm\nAdd&Norm\nMulti-Head\nFeed\n Attention \nForward\nNx\nAdd&Norm\nNx\nAdd&Norm\nMasked\nMulti-Head\n Multi-Head \n Attention \n Attention\nPositional\nPositional\nEncoding\n Encoding\nInput \n Output\nEmbedding\nEmbedding\nInputs \nOutputs(shifted right)",
    "content_ltks": "most competit neural sequenc transduct model have an encod decod structur 52 35 here the encod map an input sequenc of symbol represent 1 n to a sequenceof continu represent z z1 zn given z the decod then gener an outputsequ y1 ym of symbol one element at a time at each step the model is auto regress 10 consum the previous gener symbol a addit input when gener the next the transform follow thi overal architectur use stack self attent and point wise fullyconnect layer for both the encod and decod shown in the left and right half of figur 1 respect outputprobabilitiessoftmax add normfeedforwardadd norm add norm multi head feed attent forward nx add norm nx add norm mask multi head multi head attent attent posit posit encod encod input output embed embed input output shift right",
    "content_sm_ltks": "most competit neural sequenc transduct model have an encod decod structur 52 35 here the encod map an input sequenc of symbol represent 1 n to a sequenceof continu represent z z1 zn given z the decod then gener an outputsequ y1 ym of symbol one element at a time at each step the model is auto regress 10 consum the previous gener symbol a addit input when gener the next the transform follow thi overal architectur use stack self attent and point wise fullyconnect layer for both the encod and decod shown in the left and right half of figur 1 respect outputprobabilitiessoftmax add normfeedforwardadd norm add norm multi head feed attent forward nx add norm nx add norm mask multi head multi head attent attent posit posit encod encod input output embed embed input output shift right"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=579x734 at 0x265D0265F90>",
    "page_num_int": [
      3
    ],
    "position_int": [
      [
        3,
        208,
        401,
        404,
        415
      ]
    ],
    "top_int": [
      404
    ],
    "content_with_weight": "Figure 1: The Transformer - model architecture.",
    "content_ltks": "figur 1 the transform model architectur",
    "content_sm_ltks": "figur 1 the transform model architectur"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1203x976 at 0x265D02641F0>",
    "page_num_int": [
      3,
      3
    ],
    "position_int": [
      [
        3,
        107,
        508,
        442,
        453
      ],
      [
        3,
        104,
        505,
        464,
        543
      ]
    ],
    "top_int": [
      442,
      464
    ],
    "content_with_weight": "3.1Encoder and DecoderStacks\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has twosub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-wise fully connected feed-forward network. We employ a residual connection [11] around each ofthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer isLayerNorm(c + Sublayer(x)), where Sublayer(c) is the function implemented by the sub-layeritself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension dmodel = 512.",
    "content_ltks": "3 1encod and decoderstack encod the encod is compos of a stack of n 6 ident layer each layer ha twosub layer the first is a multi head self attent mechan and the second is a simpl posit wise fulli connect feed forward network we employ a residu connect 11 around each ofth two sub layer follow by layer normal 1 that is the output of each sub layer islayernorm c sublay x where sublay c is the function implement by the sub layeritself to facilit these residu connect all sub layer in the model a well a the embed layer produc output of dimens dmodel 512",
    "content_sm_ltks": "3 1encod and decoderstack encod the encod is compos of a stack of n 6 ident layer each layer ha twosub layer the first is a multi head self attent mechan and the second is a simpl posit wise fulli connect feed forward network we employ a residu connect 11 around each ofth two sub layer follow by layer normal 1 that is the output of each sub layer islayernorm c sublay x where sublay c is the function implement by the sub layeritself to facilit these residu connect all sub layer in the model a well a the embed layer produc output of dimens dmodel 512"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1203x975 at 0x265D0265AB0>",
    "page_num_int": [
      3,
      3
    ],
    "position_int": [
      [
        3,
        107,
        508,
        442,
        453
      ],
      [
        3,
        104,
        505,
        560,
        638
      ]
    ],
    "top_int": [
      442,
      560
    ],
    "content_with_weight": "3.1Encoder and DecoderStacks\nDecoder:The decoder is also composed of a stack of N = 6 identical layers. In addition to the twosub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connectionsaround each of the sub-layers, followed by layer normalization. We also modify the self-attentionsub-layer in the decoder stack to prevent positions from attending to subsequent positions. Thismasking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position i can depend only on the known outputs at positions less than i.",
    "content_ltks": "3 1encod and decoderstack decod the decod is also compos of a stack of n 6 ident layer in addit to the twosub layer in each encod layer the decod insert a third sub layer which perform multi head attent over the output of the encod stack similar to the encod we employ residu connectionsaround each of the sub layer follow by layer normal we also modifi the self attentionsub layer in the decod stack to prevent posit from attend to subsequ posit thismask combin with fact that the output embed are offset by one posit ensur that the predict for posit i can depend onli on the known output at posit less than i",
    "content_sm_ltks": "3 1encod and decoderstack decod the decod is also compos of a stack of n 6 ident layer in addit to the twosub layer in each encod layer the decod insert a third sub layer which perform multi head attent over the output of the encod stack similar to the encod we employ residu connectionsaround each of the sub layer follow by layer normal we also modifi the self attentionsub layer in the decod stack to prevent posit from attend to subsequ posit thismask combin with fact that the output embed are offset by one posit ensur that the predict for posit i can depend onli on the known output at posit less than i"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1205x726 at 0x265D02667D0>",
    "page_num_int": [
      3,
      3
    ],
    "position_int": [
      [
        3,
        106,
        507,
        656,
        667
      ],
      [
        3,
        104,
        506,
        677,
        723
      ]
    ],
    "top_int": [
      656,
      677
    ],
    "content_with_weight": "3.2Attention\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of thequery with the corresponding key.",
    "content_ltks": "3 2attent an attent function can be describ a map a queri and a set of key valu pair to an output where the queri key valu and output are all vector the output is comput a a weight sum of the valu where the weight assign to each valu is comput by a compat function of thequeri with the correspond key",
    "content_sm_ltks": "3 2attent an attent function can be describ a map a queri and a set of key valu pair to an output where the queri key valu and output are all vector the output is comput a a weight sum of the valu where the weight assign to each valu is comput by a compat function of thequeri with the correspond key"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=267x843 at 0x265D0266170>",
    "page_num_int": [
      3,
      4
    ],
    "position_int": [
      [
        3,
        106,
        195,
        656,
        667
      ],
      [
        4,
        362,
        451,
        70,
        103
      ]
    ],
    "top_int": [
      656,
      70
    ],
    "content_with_weight": "3.2Attention\nMulti-Head AttentionLinear",
    "content_ltks": "3 2attent multi head attentionlinear",
    "content_sm_ltks": "3 2attent multi head attentionlinear"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=197x759 at 0x265D02642B0>",
    "page_num_int": [
      3,
      4
    ],
    "position_int": [
      [
        3,
        106,
        172,
        656,
        667
      ],
      [
        4,
        204,
        270,
        107,
        113
      ]
    ],
    "top_int": [
      656,
      107
    ],
    "content_with_weight": "3.2Attention\nMatMu",
    "content_ltks": "3 2attent matmu",
    "content_sm_ltks": "3 2attent matmu"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=197x777 at 0x265D0265C00>",
    "page_num_int": [
      3,
      4
    ],
    "position_int": [
      [
        3,
        106,
        172,
        656,
        667
      ],
      [
        4,
        381,
        446,
        118,
        129
      ]
    ],
    "top_int": [
      656,
      118
    ],
    "content_with_weight": "3.2Attention\n[Concat",
    "content_ltks": "3 2attent concat",
    "content_sm_ltks": "3 2attent concat"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=197x836 at 0x265D02662C0>",
    "page_num_int": [
      3,
      4
    ],
    "position_int": [
      [
        3,
        106,
        172,
        656,
        667
      ],
      [
        4,
        175,
        240,
        124,
        155
      ]
    ],
    "top_int": [
      656,
      124
    ],
    "content_with_weight": "3.2Attention\nSoftMaxâ†‘Mask (opt.)",
    "content_ltks": "3 2attent softmax mask opt",
    "content_sm_ltks": "3 2attent softmax mask opt"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=197x767 at 0x265D02662F0>",
    "page_num_int": [
      3,
      4
    ],
    "position_int": [
      [
        3,
        106,
        172,
        656,
        667
      ],
      [
        4,
        366,
        431,
        150,
        158
      ]
    ],
    "top_int": [
      656,
      150
    ],
    "content_with_weight": "3.2Attention\nScaledDot-Product",
    "content_ltks": "3 2attent scaleddot product",
    "content_sm_ltks": "3 2attent scaleddot product"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=197x766 at 0x265D0266380>",
    "page_num_int": [
      3,
      4
    ],
    "position_int": [
      [
        3,
        106,
        172,
        656,
        667
      ],
      [
        4,
        384,
        449,
        159,
        167
      ]
    ],
    "top_int": [
      656,
      159
    ],
    "content_with_weight": "3.2Attention\nAttention",
    "content_ltks": "3 2attent attent",
    "content_sm_ltks": "3 2attent attent"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=197x836 at 0x265D0265A80>",
    "page_num_int": [
      3,
      4
    ],
    "position_int": [
      [
        3,
        106,
        172,
        656,
        667
      ],
      [
        4,
        178,
        243,
        166,
        198
      ]
    ],
    "top_int": [
      656,
      166
    ],
    "content_with_weight": "3.2Attention\nScaleMatMul",
    "content_ltks": "3 2attent scalematmul",
    "content_sm_ltks": "3 2attent scalematmul"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1195x811 at 0x265D0264520>",
    "page_num_int": [
      3,
      4
    ],
    "position_int": [
      [
        3,
        106,
        504,
        656,
        667
      ],
      [
        4,
        106,
        504,
        274,
        297
      ]
    ],
    "top_int": [
      656,
      274
    ],
    "content_with_weight": "3.2Attention\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several attention layers running in parallel.",
    "content_ltks": "3 2attent figur 2 left scale dot product attent right multi head attent consist of sever attent layer run in parallel",
    "content_sm_ltks": "3 2attent figur 2 left scale dot product attent right multi head attent consist of sever attent layer run in parallel"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1202x875 at 0x265D02645E0>",
    "page_num_int": [
      4,
      4
    ],
    "position_int": [
      [
        4,
        106,
        506,
        318,
        329
      ],
      [
        4,
        105,
        506,
        337,
        382
      ]
    ],
    "top_int": [
      318,
      337
    ],
    "content_with_weight": "3.2.1 Scaled Dot-Product Attention\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists ofqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of thequery with all keys, divide each by dk, and apply a softmax function to obtain the weights on thevalues.",
    "content_ltks": "321 scale dot product attent we call our particular attent scale dot product attent figur 2 the input consist ofqueri and key of dimens dk and valu of dimens dv we comput the dot product of thequeri with all key divid each by dk and appli a softmax function to obtain the weight on thevalu",
    "content_sm_ltks": "321 scale dot product attent we call our particular attent scale dot product attent figur 2 the input consist ofqueri and key of dimens dk and valu of dimens dv we comput the dot product of thequeri with all key divid each by dk and appli a softmax function to obtain the weight on thevalu"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1203x936 at 0x265D0266110>",
    "page_num_int": [
      4,
      4
    ],
    "position_int": [
      [
        4,
        106,
        507,
        318,
        329
      ],
      [
        4,
        104,
        505,
        384,
        449
      ]
    ],
    "top_int": [
      318,
      384
    ],
    "content_with_weight": "3.2.1 Scaled Dot-Product Attention\n In practice, we compute the attention function on a set of queries simultaneously, packed togetherinto a matrix Q. The keys and values are also packed together into matrices K and V. We computethe matrix of outputs as:QKT",
    "content_ltks": "321 scale dot product attent in practic we comput the attent function on a set of queri simultan pack togetherinto a matrix q the key and valu are also pack togeth into matrix k and v we computeth matrix of output a qkt",
    "content_sm_ltks": "321 scale dot product attent in practic we comput the attent function on a set of queri simultan pack togetherinto a matrix q the key and valu are also pack togeth into matrix k and v we computeth matrix of output a qkt"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=477x776 at 0x265D02660B0>",
    "page_num_int": [
      4,
      4
    ],
    "position_int": [
      [
        4,
        106,
        265,
        318,
        329
      ],
      [
        4,
        219,
        378,
        443,
        454
      ]
    ],
    "top_int": [
      318,
      443
    ],
    "content_with_weight": "3.2.1 Scaled Dot-Product Attention\nAttention(Q, K, V) = softmax(",
    "content_ltks": "321 scale dot product attent attent q k v softmax",
    "content_sm_ltks": "321 scale dot product attent attent q k v softmax"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=477x771 at 0x265D02663B0>",
    "page_num_int": [
      4,
      4
    ],
    "position_int": [
      [
        4,
        106,
        265,
        318,
        329
      ],
      [
        4,
        377,
        536,
        443,
        453
      ]
    ],
    "top_int": [
      318,
      443
    ],
    "content_with_weight": "3.2.1 Scaled Dot-Product Attention\n)V",
    "content_ltks": "321 scale dot product attent v",
    "content_sm_ltks": "321 scale dot product attent v"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=477x773 at 0x265D02660E0>",
    "page_num_int": [
      4,
      4
    ],
    "position_int": [
      [
        4,
        106,
        265,
        318,
        329
      ],
      [
        4,
        490,
        649,
        444,
        454
      ]
    ],
    "top_int": [
      318,
      444
    ],
    "content_with_weight": "3.2.1 Scaled Dot-Product Attention\n(1)",
    "content_ltks": "321 scale dot product attent 1",
    "content_sm_ltks": "321 scale dot product attent 1"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=477x778 at 0x265D0266230>",
    "page_num_int": [
      4,
      4
    ],
    "position_int": [
      [
        4,
        106,
        265,
        318,
        329
      ],
      [
        4,
        357,
        516,
        449,
        462
      ]
    ],
    "top_int": [
      318,
      449
    ],
    "content_with_weight": "3.2.1 Scaled Dot-Product Attention\nâˆšdk",
    "content_ltks": "321 scale dot product attent dk",
    "content_sm_ltks": "321 scale dot product attent dk"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1202x944 at 0x265D0266050>",
    "page_num_int": [
      4,
      4
    ],
    "position_int": [
      [
        4,
        106,
        507,
        318,
        329
      ],
      [
        4,
        105,
        505,
        471,
        538
      ]
    ],
    "top_int": [
      318,
      471
    ],
    "content_with_weight": "3.2.1 Scaled Dot-Product Attention\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-plicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor . Additive attention computes the compatibility function using a feed-forward network withO1Vdka single hidden layer. While the two are similar in theoretical complexity, dot-product attention ismuch faster and more space-efficient in practice, since it can be implemented using highly optimized matrix multiplication code.",
    "content_ltks": "321 scale dot product attent the two most commonli use attent function are addit attent 2 and dot product multi plic attent dot product attent is ident to our algorithm except for the scale factor addit attent comput the compat function use a feed forward network witho1vdka singl hidden layer while the two are similar in theoret complex dot product attent ismuch faster and more space effici in practic sinc it can be implement use highli optim matrix multipl code",
    "content_sm_ltks": "321 scale dot product attent the two most commonli use attent function are addit attent 2 and dot product multi plic attent dot product attent is ident to our algorithm except for the scale factor addit attent comput the compat function use a feed forward network witho1vdka singl hidden layer while the two are similar in theoret complex dot product attent ismuch faster and more space effici in practic sinc it can be implement use highli optim matrix multipl code"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1207x884 at 0x265D0266200>",
    "page_num_int": [
      4,
      4
    ],
    "position_int": [
      [
        4,
        106,
        508,
        318,
        329
      ],
      [
        4,
        103,
        505,
        543,
        591
      ]
    ],
    "top_int": [
      318,
      543
    ],
    "content_with_weight": "3.2.1 Scaled Dot-Product Attention\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms dot product attention without scaling for larger values of d [3]. We suspect that for large values of dk, the dot products grow large in magnitude, pushing the softmax function into regions where it hasextremely small gradients  To counteract tiseffect, we scale the dot products bys",
    "content_ltks": "321 scale dot product attent while for small valu of dk the two mechan perform similarli addit attent outperform dot product attent without scale for larger valu of d3 we suspect that for larg valu of dk the dot product grow larg in magnitud push the softmax function into region where it hasextrem small gradient to counteract tiseffect we scale the dot product by",
    "content_sm_ltks": "321 scale dot product attent while for small valu of dk the two mechan perform similarli addit attent outperform dot product attent without scale for larger valu of d3 we suspect that for larg valu of dk the dot product grow larg in magnitud push the softmax function into region where it hasextrem small gradient to counteract tiseffect we scale the dot product by"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x890 at 0x265D0265E10>",
    "page_num_int": [
      4,
      4
    ],
    "position_int": [
      [
        4,
        105,
        505,
        603,
        614
      ],
      [
        4,
        105,
        505,
        623,
        690
      ]
    ],
    "top_int": [
      603,
      623
    ],
    "content_with_weight": "3.2.2Multi-Head Attention\n Instead of performing a single attention function with dmodel-dimensional keys, values and queries,we found it beneficial to linearly project the queries, keys and values h times with different, learnedlinear projections to d, dk and d, dimensions, respectively. On each of these projected versions ofqueries, keys and values we then perform the attention function in parallel, yielding d, -dimensionaloutput values. These are concatenated and once again projected, resulting in the final values, asdepicted in Figure 2.",
    "content_ltks": "32 2multi head attent instead of perform a singl attent function with dmodel dimension key valu and queri we found it benefici to linearli project the queri key and valu h time with differ learnedlinear project to d dk and d dimens respect on each of these project version ofqueri key and valu we then perform the attent function in parallel yield d dimensionaloutput valu these are concaten and onc again project result in the final valu asdepict in figur 2",
    "content_sm_ltks": "32 2multi head attent instead of perform a singl attent function with dmodel dimension key valu and queri we found it benefici to linearli project the queri key and valu h time with differ learnedlinear project to d dk and d dimens respect on each of these project version ofqueri key and valu we then perform the attent function in parallel yield d dimensionaloutput valu these are concaten and onc again project result in the final valu asdepict in figur 2"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x660 at 0x265D0264100>",
    "page_num_int": [
      4,
      4
    ],
    "position_int": [
      [
        4,
        105,
        503,
        603,
        614
      ],
      [
        4,
        107,
        504,
        699,
        725
      ]
    ],
    "top_int": [
      603,
      699
    ],
    "content_with_weight": "3.2.2Multi-Head Attention\n4To illustrate why the dot products get large, assume that the components of q and k are independent randomvariables with mean O and variance 1. Then their dot product, q Â· k = >1 qiki, has mean O and variance dk.",
    "content_ltks": "32 2multi head attent 4to illustr whi the dot product get larg assum that the compon of q and k are independ randomvari with mean o and varianc 1 then their dot product q k 1 qiki ha mean o and varianc dk",
    "content_sm_ltks": "32 2multi head attent 4to illustr whi the dot product get larg assum that the compon of q and k are independ randomvari with mean o and varianc 1 then their dot product q k 1 qiki ha mean o and varianc dk"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x812 at 0x265D0266080>",
    "page_num_int": [
      4,
      5
    ],
    "position_int": [
      [
        4,
        105,
        503,
        603,
        614
      ],
      [
        5,
        107,
        504,
        74,
        97
      ]
    ],
    "top_int": [
      603,
      74
    ],
    "content_with_weight": "3.2.2Multi-Head Attention\nMulti-head attention allows the model to jointly attend to information from different representationsubspaces at different positions. With a single attention head, averaging inhibits this.",
    "content_ltks": "32 2multi head attent multi head attent allow the model to jointli attend to inform from differ representationsubspac at differ posit with a singl attent head averag inhibit thi",
    "content_sm_ltks": "32 2multi head attent multi head attent allow the model to jointli attend to inform from differ representationsubspac at differ posit with a singl attent head averag inhibit thi"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=719x835 at 0x265D02661A0>",
    "page_num_int": [
      4,
      5
    ],
    "position_int": [
      [
        4,
        105,
        345,
        603,
        614
      ],
      [
        5,
        185,
        425,
        113,
        143
      ]
    ],
    "top_int": [
      603,
      113
    ],
    "content_with_weight": "3.2.2Multi-Head Attention\nMultiHead(Q, K, V) = Concat(head1, , headn)WOwhere head; = Attention(QW, KWK, VW)",
    "content_ltks": "32 2multi head attent multihead q k v concat head1 headn wowher head attent qw kwk vw",
    "content_sm_ltks": "32 2multi head attent multihead q k v concat head1 headn wowher head attent qw kwk vw"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1197x824 at 0x265D0266020>",
    "page_num_int": [
      4,
      5
    ],
    "position_int": [
      [
        4,
        105,
        504,
        603,
        614
      ],
      [
        5,
        104,
        503,
        166,
        193
      ]
    ],
    "top_int": [
      603,
      166
    ],
    "content_with_weight": "3.2.2Multi-Head Attention\nWhere the projections are parameter matrices WQ E Rdnodelxds , WK E Rdnodel xds, WV E Rdnodel Xdyand WO E IRhdy xdmodel.",
    "content_ltks": "32 2multi head attent where the project are paramet matrix wq e rdnodelxd wk e rdnodel xd wv e rdnodel xdyand wo e irhdi xdmodel",
    "content_sm_ltks": "32 2multi head attent where the project are paramet matrix wq e rdnodelxd wk e rdnodel xd wv e rdnodel xdyand wo e irhdi xdmodel"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1195x844 at 0x265D0266350>",
    "page_num_int": [
      4,
      5
    ],
    "position_int": [
      [
        4,
        105,
        504,
        603,
        614
      ],
      [
        5,
        106,
        504,
        197,
        231
      ]
    ],
    "top_int": [
      603,
      197
    ],
    "content_with_weight": "3.2.2Multi-Head Attention\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we usedk = d = dmodel/h = 64. Due to the reduced dimension of each head, the total computational costis similar to that of single-head attention with full dimensionality.",
    "content_ltks": "32 2multi head attent in thi work we employ h 8 parallel attent layer or head for each of these we usedk d dmodel h 64 due to the reduc dimens of each head the total comput costi similar to that of singl head attent with full dimension",
    "content_sm_ltks": "32 2multi head attent in thi work we employ h 8 parallel attent layer or head for each of these we usedk d dmodel h 64 due to the reduc dimens of each head the total comput costi similar to that of singl head attent with full dimension"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1197x871 at 0x265D0266320>",
    "page_num_int": [
      5,
      5
    ],
    "position_int": [
      [
        5,
        107,
        506,
        241,
        252
      ],
      [
        5,
        105,
        504,
        257,
        301
      ]
    ],
    "top_int": [
      241,
      257
    ],
    "content_with_weight": "3.2.3Applications of Attention in our Model\nThe Transformer uses multi-head attention in three different ways:Â· In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,and the memory keys and values come from the output of the encoder. This allows every",
    "content_ltks": "32 3applic of attent in our model the transform us multi head attent in three differ way in encod decod attent layer the queri come from the previou decod layer and the memori key and valu come from the output of the encod thi allow everi",
    "content_sm_ltks": "32 3applic of attent in our model the transform us multi head attent in three differ way in encod decod attent layer the queri come from the previou decod layer and the memori key and valu come from the output of the encod thi allow everi"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1087x839 at 0x265D0266860>",
    "page_num_int": [
      5,
      5
    ],
    "position_int": [
      [
        5,
        107,
        469,
        241,
        252
      ],
      [
        5,
        142,
        504,
        301,
        334
      ]
    ],
    "top_int": [
      241,
      301
    ],
    "content_with_weight": "3.2.3Applications of Attention in our Model\nposition in the decoder to attend over all positions in the input sequence. This mimics thetypical encoder-decoder attention mechanisms in sequence-to-sequence models such as[38, 2, 9].",
    "content_ltks": "32 3applic of attent in our model posit in the decod to attend over all posit in the input sequenc thi mimic thetyp encod decod attent mechan in sequenc to sequenc model such a 38 29",
    "content_sm_ltks": "32 3applic of attent in our model posit in the decod to attend over all posit in the input sequenc thi mimic thetyp encod decod attent mechan in sequenc to sequenc model such a 38 29"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1115x868 at 0x265D0265F00>",
    "page_num_int": [
      5,
      5
    ],
    "position_int": [
      [
        5,
        107,
        479,
        241,
        252
      ],
      [
        5,
        133,
        504,
        336,
        379
      ]
    ],
    "top_int": [
      241,
      336
    ],
    "content_with_weight": "3.2.3Applications of Attention in our Model\nÂ· The encoder contains self-attention layers. In a self-attention layer all of the keys, valuesand queries come from the same place, in this case, the output of the previous layer in theencoder. Each position in the encoder can attend to all positions in the previous layer of theencoder.",
    "content_ltks": "32 3applic of attent in our model the encod contain self attent layer in a self attent layer all of the key valuesand queri come from the same place in thi case the output of the previou layer in theencod each posit in the encod can attend to all posit in the previou layer of theencod",
    "content_sm_ltks": "32 3applic of attent in our model the encod contain self attent layer in a self attent layer all of the key valuesand queri come from the same place in thi case the output of the previou layer in theencod each posit in the encod can attend to all posit in the previou layer of theencod"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1115x906 at 0x265D0266830>",
    "page_num_int": [
      5,
      5
    ],
    "position_int": [
      [
        5,
        107,
        479,
        241,
        252
      ],
      [
        5,
        133,
        504,
        383,
        439
      ]
    ],
    "top_int": [
      241,
      383
    ],
    "content_with_weight": "3.2.3Applications of Attention in our Model\nÂ· Similarly, self-attention layers in the decoder allow each position in the decoder to attend toall positions in the decoder up to and including that position. We need to prevent leftwardinformation flow in the decoder to preserve the auto-regressive property. We implement thisinside of scaled dot-product attention by masking out (setting to --oo) all values in the inputof the softmax which correspond to illegal connections. See Figure 2.",
    "content_ltks": "32 3applic of attent in our model similarli self attent layer in the decod allow each posit in the decod to attend toall posit in the decod up to and includ that posit we need to prevent leftwardinform flow in the decod to preserv the auto regress properti we implement thisinsid of scale dot product attent by mask out set to oo all valu in the inputof the softmax which correspond to illeg connect see figur 2",
    "content_sm_ltks": "32 3applic of attent in our model similarli self attent layer in the decod allow each posit in the decod to attend toall posit in the decod up to and includ that posit we need to prevent leftwardinform flow in the decod to preserv the auto regress properti we implement thisinsid of scale dot product attent by mask out set to oo all valu in the inputof the softmax which correspond to illeg connect see figur 2"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1195x845 at 0x265D02661D0>",
    "page_num_int": [
      5,
      5
    ],
    "position_int": [
      [
        5,
        107,
        505,
        450,
        462
      ],
      [
        5,
        106,
        504,
        471,
        505
      ]
    ],
    "top_int": [
      450,
      471
    ],
    "content_with_weight": "3.3Position-wise Feed-Forward Networks\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fullyconnected feed-forward network, which is applied to each position separately and identically. Thisconsists of two linear transformations with a ReLU activation in between.",
    "content_ltks": "3 3posit wise feed forward network in addit to attent sub layer each of the layer in our encod and decod contain a fullyconnect feed forward network which is appli to each posit separ and ident thisconsist of two linear transform with a relu activ in between",
    "content_sm_ltks": "3 3posit wise feed forward network in addit to attent sub layer each of the layer in our encod and decod contain a fullyconnect feed forward network which is appli to each posit separ and ident thisconsist of two linear transform with a relu activ in between"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=561x778 at 0x265D0266770>",
    "page_num_int": [
      5,
      5
    ],
    "position_int": [
      [
        5,
        107,
        294,
        450,
        462
      ],
      [
        5,
        226,
        413,
        519,
        531
      ]
    ],
    "top_int": [
      450,
      519
    ],
    "content_with_weight": "3.3Position-wise Feed-Forward Networks\nFFN(Î±) = max(0, cW1 + b1)W2 + b2",
    "content_ltks": "3 3posit wise feed forward network ffn Î± max 0 cw1 b1 w2 b2",
    "content_sm_ltks": "3 3posit wise feed forward network ffn Î± max 0 cw1 b1 w2 b2"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=561x775 at 0x265D0266680>",
    "page_num_int": [
      5,
      5
    ],
    "position_int": [
      [
        5,
        107,
        294,
        450,
        462
      ],
      [
        5,
        491,
        678,
        520,
        531
      ]
    ],
    "top_int": [
      450,
      520
    ],
    "content_with_weight": "3.3Position-wise Feed-Forward Networks\n(2)",
    "content_ltks": "3 3posit wise feed forward network 2",
    "content_sm_ltks": "3 3posit wise feed forward network 2"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x810 at 0x265D02667A0>",
    "page_num_int": [
      5,
      5
    ],
    "position_int": [
      [
        5,
        107,
        504,
        450,
        462
      ],
      [
        5,
        107,
        504,
        538,
        560
      ]
    ],
    "top_int": [
      450,
      538
    ],
    "content_with_weight": "3.3Position-wise Feed-Forward Networks\nWhile the linear transformations are the same across different positions, they use different parametersfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.",
    "content_ltks": "3 3posit wise feed forward network while the linear transform are the same across differ posit they use differ parametersfrom layer to layer anoth way of describ thi is a two convolut with kernel size 1",
    "content_sm_ltks": "3 3posit wise feed forward network while the linear transform are the same across differ posit they use differ parametersfrom layer to layer anoth way of describ thi is a two convolut with kernel size 1"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x822 at 0x265D02666E0>",
    "page_num_int": [
      5,
      5
    ],
    "position_int": [
      [
        5,
        107,
        507,
        450,
        462
      ],
      [
        5,
        104,
        504,
        557,
        583
      ]
    ],
    "top_int": [
      450,
      557
    ],
    "content_with_weight": "3.3Position-wise Feed-Forward Networks\n The dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionalitydff=2048.",
    "content_ltks": "3 3posit wise feed forward network the dimension of input and output is dmodel 512 and the inner layer ha dimensionalitydff 2048",
    "content_sm_ltks": "3 3posit wise feed forward network the dimension of input and output is dmodel 512 and the inner layer ha dimensionalitydff 2048"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x917 at 0x265D0266740>",
    "page_num_int": [
      5,
      5
    ],
    "position_int": [
      [
        5,
        106,
        506,
        593,
        604
      ],
      [
        5,
        105,
        505,
        612,
        670
      ]
    ],
    "top_int": [
      593,
      612
    ],
    "content_with_weight": "3.4 Embeddings and Softmax\nSimilarly to other sequence transduction models, we use learned embeddings to convert the inputtokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-mation and softmax function to convert the decoder output to predicted next-token probabilities. Inour model, we share the same weight matrix between the two embedding layers and the pre-softmaxlinear transformation, similar to [30]. In the embedding layers, we multiply those weights by dmodel.",
    "content_ltks": "34 embed and softmax similarli to other sequenc transduct model we use learn embed to convert the inputtoken and output token to vector of dimens dmodel we also use the usual learn linear transfor mation and softmax function to convert the decod output to predict next token probabl inour model we share the same weight matrix between the two embed layer and the pre softmaxlinear transform similar to 30 in the embed layer we multipli those weight by dmodel",
    "content_sm_ltks": "34 embed and softmax similarli to other sequenc transduct model we use learn embed to convert the inputtoken and output token to vector of dimens dmodel we also use the usual learn linear transfor mation and softmax function to convert the decod output to predict next token probabl inour model we share the same weight matrix between the two embed layer and the pre softmaxlinear transform similar to 30 in the embed layer we multipli those weight by dmodel"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1190x665 at 0x265D02666B0>",
    "page_num_int": [
      5,
      5
    ],
    "position_int": [
      [
        5,
        105,
        501,
        679,
        693
      ],
      [
        5,
        107,
        504,
        700,
        725
      ]
    ],
    "top_int": [
      679,
      700
    ],
    "content_with_weight": "3.5Positional Encoding\nSince our model contains no recurrence and no convolution, in order for the model to make use of theorder of the sequence, we must inject some information about the relative or absolute position of the",
    "content_ltks": "3 5posit encod sinc our model contain no recurr and no convolut in order for the model to make use of theorder of the sequenc we must inject some inform about the rel or absolut posit of the",
    "content_sm_ltks": "3 5posit encod sinc our model contain no recurr and no convolut in order for the model to make use of theorder of the sequenc we must inject some inform about the rel or absolut posit of the"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1193x852 at 0x265D0266620>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        502,
        679,
        693
      ],
      [
        6,
        106,
        504,
        70,
        104
      ]
    ],
    "top_int": [
      679,
      70
    ],
    "content_with_weight": "3.5Positional Encoding\nTable 1: Maximum path lengths, per-layer complexity and minimum number of sequential operationsfor different layer types. n is the sequence length, d is the representation dimension, k is the kernelsize of convolutions and r the size of the neighborhood in restricted self-attention.",
    "content_ltks": "3 5posit encod tabl 1 maximum path length per layer complex and minimum number of sequenti operationsfor differ layer type n is the sequenc length d is the represent dimens k is the kernels of convolut and r the size of the neighborhood in restrict self attent",
    "content_sm_ltks": "3 5posit encod tabl 1 maximum path length per layer complex and minimum number of sequenti operationsfor differ layer type n is the sequenc length d is the represent dimens k is the kernels of convolut and r the size of the neighborhood in restrict self attent"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x792 at 0x265D0266650>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        121,
        233,
        113,
        127
      ]
    ],
    "top_int": [
      679,
      113
    ],
    "content_with_weight": "3.5Positional Encoding\n Layer Type",
    "content_ltks": "3 5posit encod layer type",
    "content_sm_ltks": "3 5posit encod layer type"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x785 at 0x265D02665C0>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        239,
        351,
        116,
        128
      ]
    ],
    "top_int": [
      679,
      116
    ],
    "content_with_weight": "3.5Positional Encoding\nComplexity per Layer",
    "content_ltks": "3 5posit encod complex per layer",
    "content_sm_ltks": "3 5posit encod complex per layer"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x788 at 0x265D0266710>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        337,
        449,
        116,
        129
      ]
    ],
    "top_int": [
      679,
      116
    ],
    "content_with_weight": "3.5Positional Encoding\n Sequential",
    "content_ltks": "3 5posit encod sequenti",
    "content_sm_ltks": "3 5posit encod sequenti"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x782 at 0x265D02665F0>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        392,
        504,
        116,
        127
      ]
    ],
    "top_int": [
      679,
      116
    ],
    "content_with_weight": "3.5Positional Encoding\nMaximum Path Length",
    "content_ltks": "3 5posit encod maximum path length",
    "content_sm_ltks": "3 5posit encod maximum path length"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x785 at 0x265D0266560>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        338,
        450,
        127,
        138
      ]
    ],
    "top_int": [
      679,
      127
    ],
    "content_with_weight": "3.5Positional Encoding\nOperations",
    "content_ltks": "3 5posit encod oper",
    "content_sm_ltks": "3 5posit encod oper"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x785 at 0x265D0266500>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        122,
        234,
        137,
        149
      ]
    ],
    "top_int": [
      679,
      137
    ],
    "content_with_weight": "3.5Positional Encoding\nSelf-Attention",
    "content_ltks": "3 5posit encod self attent",
    "content_sm_ltks": "3 5posit encod self attent"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x795 at 0x265D0266590>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        261,
        373,
        135,
        150
      ]
    ],
    "top_int": [
      679,
      135
    ],
    "content_with_weight": "3.5Positional Encoding\nO(n2 . d)",
    "content_ltks": "3 5posit encod o n2 d",
    "content_sm_ltks": "3 5posit encod o n2 d"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x787 at 0x265D02664D0>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        349,
        461,
        138,
        151
      ]
    ],
    "top_int": [
      679,
      138
    ],
    "content_with_weight": "3.5Positional Encoding\n0(1)",
    "content_ltks": "3 5posit encod 01",
    "content_sm_ltks": "3 5posit encod 01"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x787 at 0x265D0266470>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        429,
        541,
        138,
        151
      ]
    ],
    "top_int": [
      679,
      138
    ],
    "content_with_weight": "3.5Positional Encoding\n0(1)",
    "content_ltks": "3 5posit encod 01",
    "content_sm_ltks": "3 5posit encod 01"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x785 at 0x265D02664A0>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        123,
        235,
        151,
        162
      ]
    ],
    "top_int": [
      679,
      151
    ],
    "content_with_weight": "3.5Positional Encoding\nRecurrent",
    "content_ltks": "3 5posit encod recurr",
    "content_sm_ltks": "3 5posit encod recurr"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x794 at 0x265D0266440>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        261,
        373,
        149,
        164
      ]
    ],
    "top_int": [
      679,
      149
    ],
    "content_with_weight": "3.5Positional Encoding\nO(n . dÂ²)",
    "content_ltks": "3 5posit encod o n d Â²",
    "content_sm_ltks": "3 5posit encod o n d Â²"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x788 at 0x265D02663E0>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        349,
        461,
        150,
        162
      ]
    ],
    "top_int": [
      679,
      150
    ],
    "content_with_weight": "3.5Positional Encoding\nO(n)",
    "content_ltks": "3 5posit encod o n",
    "content_sm_ltks": "3 5posit encod o n"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x788 at 0x265D0266890>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        429,
        541,
        150,
        162
      ]
    ],
    "top_int": [
      679,
      150
    ],
    "content_with_weight": "3.5Positional Encoding\nO(n)",
    "content_ltks": "3 5posit encod o n",
    "content_sm_ltks": "3 5posit encod o n"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x785 at 0x265D0266530>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        123,
        235,
        161,
        173
      ]
    ],
    "top_int": [
      679,
      161
    ],
    "content_with_weight": "3.5Positional Encoding\nConvolutional",
    "content_ltks": "3 5posit encod convolut",
    "content_sm_ltks": "3 5posit encod convolut"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x790 at 0x265D0266800>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        256,
        368,
        161,
        175
      ]
    ],
    "top_int": [
      679,
      161
    ],
    "content_with_weight": "3.5Positional Encoding\nO(k Â· n Â· dÂ²)",
    "content_ltks": "3 5posit encod o k n d Â²",
    "content_sm_ltks": "3 5posit encod o k n d Â²"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x779 at 0x265D02668C0>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        350,
        462,
        162,
        172
      ]
    ],
    "top_int": [
      679,
      162
    ],
    "content_with_weight": "3.5Positional Encoding\n0(1)",
    "content_ltks": "3 5posit encod 01",
    "content_sm_ltks": "3 5posit encod 01"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x792 at 0x265D0266A10>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        415,
        527,
        161,
        175
      ]
    ],
    "top_int": [
      679,
      161
    ],
    "content_with_weight": "3.5Positional Encoding\nO(logk(n))",
    "content_ltks": "3 5posit encod o logk n",
    "content_sm_ltks": "3 5posit encod o logk n"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x784 at 0x265D02668F0>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        122,
        234,
        173,
        184
      ]
    ],
    "top_int": [
      679,
      173
    ],
    "content_with_weight": "3.5Positional Encoding\nSelf-Attention (restricted)",
    "content_ltks": "3 5posit encod self attent restrict",
    "content_sm_ltks": "3 5posit encod self attent restrict"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x792 at 0x265D02669B0>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        258,
        370,
        170,
        184
      ]
    ],
    "top_int": [
      679,
      170
    ],
    "content_with_weight": "3.5Positional Encoding\nO(r . n Â· d)",
    "content_ltks": "3 5posit encod o r n d",
    "content_sm_ltks": "3 5posit encod o r n d"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x787 at 0x265D0266410>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        349,
        461,
        172,
        184
      ]
    ],
    "top_int": [
      679,
      172
    ],
    "content_with_weight": "3.5Positional Encoding\n0(1)",
    "content_ltks": "3 5posit encod 01",
    "content_sm_ltks": "3 5posit encod 01"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=336x787 at 0x265D0266A40>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        217,
        679,
        693
      ],
      [
        6,
        424,
        536,
        172,
        184
      ]
    ],
    "top_int": [
      679,
      172
    ],
    "content_with_weight": "3.5Positional Encoding\nO(n /r)",
    "content_ltks": "3 5posit encod o n r",
    "content_sm_ltks": "3 5posit encod o n r"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x883 at 0x265D0266BC0>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        505,
        679,
        693
      ],
      [
        6,
        105,
        505,
        213,
        257
      ]
    ],
    "top_int": [
      679,
      213
    ],
    "content_with_weight": "3.5Positional Encoding\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the bottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel as the embeddings, so that the two can be summed. There are many choices of positional encodings,learned and fixed [9].",
    "content_ltks": "3 5posit encod token in the sequenc to thi end we add posit encod to the input embed at the bottom of the encod and decod stack the posit encod have the same dimens dmodel a the embed so that the two can be sum there are mani choic of posit encod learn and fix 9",
    "content_sm_ltks": "3 5posit encod token in the sequenc to thi end we add posit encod to the input embed at the bottom of the encod and decod stack the posit encod have the same dimens dmodel a the embed so that the two can be sum there are mani choic of posit encod learn and fix 9"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=853x901 at 0x265D0266B60>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        389,
        679,
        693
      ],
      [
        6,
        105,
        390,
        260,
        310
      ]
    ],
    "top_int": [
      679,
      260
    ],
    "content_with_weight": "3.5Positional Encoding\n In this work, we use sine and cosine functions of different frequencies:PE(pos,i) = sin(pos / 100002i/dmodel)",
    "content_ltks": "3 5posit encod in thi work we use sine and cosin function of differ frequenc pe po i sin po 100002i dmodel",
    "content_sm_ltks": "3 5posit encod in thi work we use sine and cosin function of differ frequenc pe po i sin po 100002i dmodel"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=489x800 at 0x265D0266AD0>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        268,
        679,
        693
      ],
      [
        6,
        223,
        386,
        309,
        326
      ]
    ],
    "top_int": [
      679,
      309
    ],
    "content_with_weight": "3.5Positional Encoding\nPE(pos,2i+1) = cos(pos/100002i/dmodel)",
    "content_ltks": "3 5posit encod pe po 2i 1 co po 100002i dmodel",
    "content_sm_ltks": "3 5posit encod pe po 2i 1 co po 100002i dmodel"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x915 at 0x265D0266D10>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        505,
        679,
        693
      ],
      [
        6,
        105,
        505,
        332,
        387
      ]
    ],
    "top_int": [
      679,
      332
    ],
    "content_with_weight": "3.5Positional Encoding\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding corresponds to a sinusoid. The wavelengths form a geometric progression from 2Ï€ to 10000 : 2Ï€. Wechose this function because we hypothesized it would allow the model to easily learn to attend byrelative positions, since for any fixed offset k, PEpos+k can be represented as a linear function ofPEpos.",
    "content_ltks": "3 5posit encod where po is the posit and i is the dimens that is each dimens of the posit encod correspond to a sinusoid the wavelength form a geometr progress from 2 Ï€ to 10000 2 Ï€ wechos thi function becaus we hypothes it would allow the model to easili learn to attend byrel posit sinc for ani fix offset k pepo k can be repres a a linear function ofpepo",
    "content_sm_ltks": "3 5posit encod where po is the posit and i is the dimens that is each dimens of the posit encod correspond to a sinusoid the wavelength form a geometr progress from 2 Ï€ to 10000 2 Ï€ wechos thi function becaus we hypothes it would allow the model to easili learn to attend byrel posit sinc for ani fix offset k pepo k can be repres a a linear function ofpepo"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1196x883 at 0x265D0267070>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        503,
        679,
        693
      ],
      [
        6,
        106,
        504,
        393,
        438
      ]
    ],
    "top_int": [
      679,
      393
    ],
    "content_with_weight": "3.5Positional Encoding\nWe also experimented with using learned positional embeddings [9] instead, and found that the twoversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal versionbecause it may allow the model to extrapolate to sequence lengths longer than the ones encounteredduring training.",
    "content_ltks": "3 5posit encod we also experi with use learn posit embed 9 instead and found that the twovers produc nearli ident result see tabl 3 row e we chose the sinusoid versionbecaus it may allow the model to extrapol to sequenc length longer than the one encountereddur train",
    "content_sm_ltks": "3 5posit encod we also experi with use learn posit embed 9 instead and found that the twovers produc nearli ident result see tabl 3 row e we chose the sinusoid versionbecaus it may allow the model to extrapol to sequenc length longer than the one encountereddur train"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=357x785 at 0x265D0266C20>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        224,
        679,
        693
      ],
      [
        6,
        106,
        225,
        453,
        465
      ]
    ],
    "top_int": [
      679,
      453
    ],
    "content_with_weight": "3.5Positional Encoding\n4Why Self-Attention",
    "content_ltks": "3 5posit encod 4whi self attent",
    "content_sm_ltks": "3 5posit encod 4whi self attent"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1203x920 at 0x265D0266DD0>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        506,
        679,
        693
      ],
      [
        6,
        104,
        505,
        475,
        532
      ]
    ],
    "top_int": [
      679,
      475
    ],
    "content_with_weight": "3.5Positional Encoding\n In this section we compare various aspects of self-attention layers to the recurrent and convolu-tional layers commonly used for mapping one variable-length sequence of symbol representations(1, ., &n) to another sequence of equal length (z1, ., Zn), with ci, Z E Rd, such as a hiddenlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention weconsider three desiderata.",
    "content_ltks": "3 5posit encod in thi section we compar variou aspect of self attent layer to the recurr and convolu tional layer commonli use for map one variabl length sequenc of symbol represent 1 n to anoth sequenc of equal length z1 zn with ci z e rd such a a hiddenlay in a typic sequenc transduct encod or decod motiv our use of self attent weconsid three desideratum",
    "content_sm_ltks": "3 5posit encod in thi section we compar variou aspect of self attent layer to the recurr and convolu tional layer commonli use for map one variabl length sequenc of symbol represent 1 n to anoth sequenc of equal length z1 zn with ci z e rd such a a hiddenlay in a typic sequenc transduct encod or decod motiv our use of self attent weconsid three desideratum"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x825 at 0x265D0266DA0>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        505,
        679,
        693
      ],
      [
        6,
        105,
        505,
        535,
        560
      ]
    ],
    "top_int": [
      679,
      535
    ],
    "content_with_weight": "3.5Positional Encoding\n One is the total computational complexity per layer. Another is the amount of computation that canbe parallelized, as measured by the minimum number of sequential operations required.",
    "content_ltks": "3 5posit encod one is the total comput complex per layer anoth is the amount of comput that canb parallel a measur by the minimum number of sequenti oper requir",
    "content_sm_ltks": "3 5posit encod one is the total comput complex per layer anoth is the amount of comput that canb parallel a measur by the minimum number of sequenti oper requir"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1198x983 at 0x265D0266D70>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        504,
        679,
        693
      ],
      [
        6,
        106,
        505,
        563,
        641
      ]
    ],
    "top_int": [
      679,
      563
    ],
    "content_with_weight": "3.5Positional Encoding\nThe third is the path length between long-range dependencies in the network. Learning long-rangedependencies is a key challenge in many sequence transduction tasks. One key factor affecting theability to learn such dependencies is the length of the paths forward and backward signals have totraverse in the network. The shorter these paths between any combination of positions in the inputand output sequences, the easier it is to learn long-range dependencies [12]. Hence we also comparethe maximum path length between any two input and output positions in networks composed of thedifferent layer types.",
    "content_ltks": "3 5posit encod the third is the path length between long rang depend in the network learn long rangedepend is a key challeng in mani sequenc transduct task one key factor affect theabil to learn such depend is the length of the path forward and backward signal have totravers in the network the shorter these path between ani combin of posit in the inputand output sequenc the easier it is to learn long rang depend 12 henc we also compareth maximum path length between ani two input and output posit in network compos of thediffer layer type",
    "content_sm_ltks": "3 5posit encod the third is the path length between long rang depend in the network learn long rangedepend is a key challeng in mani sequenc transduct task one key factor affect theabil to learn such depend is the length of the path forward and backward signal have totravers in the network the shorter these path between ani combin of posit in the inputand output sequenc the easier it is to learn long rang depend 12 henc we also compareth maximum path length between ani two input and output posit in network compos of thediffer layer type"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1195x826 at 0x265D0266BF0>",
    "page_num_int": [
      5,
      6
    ],
    "position_int": [
      [
        5,
        105,
        503,
        679,
        693
      ],
      [
        6,
        106,
        504,
        646,
        724
      ]
    ],
    "top_int": [
      679,
      646
    ],
    "content_with_weight": "3.5Positional Encoding\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentiallyexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms ofcomputational complexity, self-attention layers are faster than recurrent layers when the sequencelength n is smaller than the representation dimensionality d, which is most often the case withsentence representations used by state-of-the-art models in machine translations, such as word-piece [38] and byte-pair [31] representations. To improve computational performance for tasks involvingvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in",
    "content_ltks": "3 5posit encod a note in tabl 1a self attent layer connect all posit with a constant number of sequentiallyexecut oper wherea a recurr layer requir o n sequenti oper in term ofcomput complex self attent layer are faster than recurr layer when the sequencelength n is smaller than the represent dimension d which is most often the case withsent represent use by state of the art model in machin translat such a word piec 38 and byte pair 31 represent to improv comput perform for task involvingveri long sequenc self attent could be restrict to consid onli a neighborhood of size r in",
    "content_sm_ltks": "3 5posit encod a note in tabl 1a self attent layer connect all posit with a constant number of sequentiallyexecut oper wherea a recurr layer requir o n sequenti oper in term ofcomput complex self attent layer are faster than recurr layer when the sequencelength n is smaller than the represent dimension d which is most often the case withsent represent use by state of the art model in machin translat such a word piec 38 and byte pair 31 represent to improv comput perform for task involvingveri long sequenc self attent could be restrict to consid onli a neighborhood of size r in"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x819 at 0x265D0266EC0>",
    "page_num_int": [
      5,
      7
    ],
    "position_int": [
      [
        5,
        105,
        502,
        679,
        693
      ],
      [
        7,
        107,
        504,
        74,
        97
      ]
    ],
    "top_int": [
      679,
      74
    ],
    "content_with_weight": "3.5Positional Encoding\nthe input sequence centered around the respective output position. This would increase the maximumpath length to O(n /r). We plan to investigate this approach further in future work.",
    "content_ltks": "3 5posit encod the input sequenc center around the respect output posit thi would increas the maximumpath length to o n r we plan to investig thi approach further in futur work",
    "content_sm_ltks": "3 5posit encod the input sequenc center around the respect output posit thi would increas the maximumpath length to o n r we plan to investig thi approach further in futur work"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x1013 at 0x265D02670D0>",
    "page_num_int": [
      5,
      7
    ],
    "position_int": [
      [
        5,
        105,
        505,
        679,
        693
      ],
      [
        7,
        105,
        505,
        101,
        189
      ]
    ],
    "top_int": [
      679,
      101
    ],
    "content_with_weight": "3.5Positional Encoding\nA single convolutional layer with kernel width k < n does not connect all pairs of input and outputpositions. Doing so requires a stack of O(n /k) convolutional layers in the case of contiguous kernels,or O(logk(n)) in the case of dilated convolutions [18], increasing the length of the longest pathsbetween any two positions in the network. Convolutional layers are generally more expensive thanrecurrent layers, by a factor of k. Separable convolutions [6], however, decrease the complexityconsiderably, to O(k n Â· d + n Â· d2). Even with k = n, however, the complexity of a separableconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,the approach we take in our model.",
    "content_ltks": "3 5posit encod a singl convolut layer with kernel width k n doe not connect all pair of input and outputposit do so requir a stack of o n k convolut layer in the case of contigu kernel or o logk n in the case of dilat convolut 18 increas the length of the longest pathsbetween ani two posit in the network convolut layer are gener more expens thanrecurr layer by a factor of k separ convolut 6 howev decreas the complexityconsider to o k n d n d2 even with k n howev the complex of a separableconvolut is equal to the combin of a self attent layer and a point wise feed forward layer the approach we take in our model",
    "content_sm_ltks": "3 5posit encod a singl convolut layer with kernel width k n doe not connect all pair of input and outputposit do so requir a stack of o n k convolut layer in the case of contigu kernel or o logk n in the case of dilat convolut 18 increas the length of the longest pathsbetween ani two posit in the network convolut layer are gener more expens thanrecurr layer by a factor of k separ convolut 6 howev decreas the complexityconsider to o k n d n d2 even with k n howev the complex of a separableconvolut is equal to the combin of a self attent layer and a point wise feed forward layer the approach we take in our model"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x879 at 0x265D0266F20>",
    "page_num_int": [
      5,
      7
    ],
    "position_int": [
      [
        5,
        105,
        505,
        679,
        693
      ],
      [
        7,
        105,
        505,
        194,
        237
      ]
    ],
    "top_int": [
      679,
      194
    ],
    "content_with_weight": "3.5Positional Encoding\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributionsfrom our models and present and discuss examples in the appendix. Not only do individual attention heads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntacticand semantic structure of the sentences.",
    "content_ltks": "3 5posit encod a side benefit self attent could yield more interpret model we inspect attent distributionsfrom our model and present and discu exampl in the appendix not onli do individu attent head clearli learn to perform differ task mani appear to exhibit behavior relat to the syntacticand semant structur of the sentenc",
    "content_sm_ltks": "3 5posit encod a side benefit self attent could yield more interpret model we inspect attent distributionsfrom our model and present and discu exampl in the appendix not onli do individu attent head clearli learn to perform differ task mani appear to exhibit behavior relat to the syntacticand semant structur of the sentenc"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=688x784 at 0x265D0267100>",
    "page_num_int": [
      7,
      7
    ],
    "position_int": [
      [
        7,
        105,
        334,
        252,
        266
      ],
      [
        7,
        107,
        336,
        280,
        292
      ]
    ],
    "top_int": [
      252,
      280
    ],
    "content_with_weight": "5  Training\nThis section describes the training regime for our models.",
    "content_ltks": "5 train thi section describ the train regim for our model",
    "content_sm_ltks": "5 train thi section describ the train regim for our model"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1195x982 at 0x265D0267280>",
    "page_num_int": [
      7,
      7
    ],
    "position_int": [
      [
        7,
        105,
        504,
        303,
        317
      ],
      [
        7,
        106,
        504,
        326,
        403
      ]
    ],
    "top_int": [
      303,
      326
    ],
    "content_with_weight": " 5.1  Training Data and Batching\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 millionsentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source-target vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piecevocabulary [38]. Sentence pairs were batched together by approximate sequence length. Each trainingbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000target tokens.",
    "content_ltks": "51 train data and batch we train on the standard wmt 2014 english german dataset consist of about 45 millionsent pair sentenc were encod use byte pair encod 3 which ha a share sourc target vocabulari of about 37000 token for english french we use the significantli larger wmt2014 english french dataset consist of 36m sentenc and split token into a 32000 word piecevocabulari 38 sentenc pair were batch togeth by approxim sequenc length each trainingbatch contain a set of sentenc pair contain approxim 25000 sourc token and 25000target token",
    "content_sm_ltks": "51 train data and batch we train on the standard wmt 2014 english german dataset consist of about 45 millionsent pair sentenc were encod use byte pair encod 3 which ha a share sourc target vocabulari of about 37000 token for english french we use the significantli larger wmt2014 english french dataset consist of 36m sentenc and split token into a 32000 word piecevocabulari 38 sentenc pair were batch togeth by approxim sequenc length each trainingbatch contain a set of sentenc pair contain approxim 25000 sourc token and 25000target token"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1198x906 at 0x265D0267220>",
    "page_num_int": [
      7,
      7
    ],
    "position_int": [
      [
        7,
        105,
        505,
        415,
        427
      ],
      [
        7,
        106,
        505,
        437,
        491
      ]
    ],
    "top_int": [
      415,
      437
    ],
    "content_with_weight": "5.2Hardware and Schedule\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models usingthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. Wetrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on thebottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps(3.5 days).",
    "content_ltks": "5 2hardwar and schedul we train our model on one machin with 8 nvidia p100 gpu for our base model usingth hyperparamet describ throughout the paper each train step took about 0 4 second wetrain the base model for a total of 100 000 step or 12 hour for our big model describ on thebottom line of tabl 3 step time wa 10 second the big model were train for 300 000 step 35 day",
    "content_sm_ltks": "5 2hardwar and schedul we train our model on one machin with 8 nvidia p100 gpu for our base model usingth hyperparamet describ throughout the paper each train step took about 0 4 second wetrain the base model for a total of 100 000 step or 12 hour for our big model describ on thebottom line of tabl 3 step time wa 10 second the big model were train for 300 000 step 35 day"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1198x911 at 0x265D0266F50>",
    "page_num_int": [
      7,
      7
    ],
    "position_int": [
      [
        7,
        106,
        506,
        505,
        517
      ],
      [
        7,
        106,
        505,
        524,
        580
      ]
    ],
    "top_int": [
      505,
      524
    ],
    "content_with_weight": "5.3Optimizer\nWe used the Adam optimizer [20] with Î²1 = 0.9, Î²2 = 0.98 and e = 10-9. We varied the learningrate over the course of training, according to the formula:lrate = dmodsa min(step_num-0.5 , step_num warmup_steps-1.5)",
    "content_ltks": "5 3optim we use the adam optim 20 with Î² 10 9 Î² 20 98 and e 10 9 we vari the learningr over the cours of train accord to the formula lrate dmodsa min step _ num 0 5 step _ num warmup _ step 15",
    "content_sm_ltks": "5 3optim we use the adam optim 20 with Î² 10 9 Î² 20 98 and e 10 9 we vari the learningr over the cours of train accord to the formula lrate dmodsa min step _ num 0 5 step _ num warmup _ step 15"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=207x775 at 0x265D02672B0>",
    "page_num_int": [
      7,
      7
    ],
    "position_int": [
      [
        7,
        106,
        175,
        505,
        517
      ],
      [
        7,
        489,
        558,
        566,
        577
      ]
    ],
    "top_int": [
      505,
      566
    ],
    "content_with_weight": "5.3Optimizer\n(3)",
    "content_ltks": "5 3optim 3",
    "content_sm_ltks": "5 3optim 3"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x852 at 0x265D0267130>",
    "page_num_int": [
      7,
      7
    ],
    "position_int": [
      [
        7,
        106,
        506,
        505,
        517
      ],
      [
        7,
        105,
        505,
        585,
        622
      ]
    ],
    "top_int": [
      505,
      585
    ],
    "content_with_weight": "5.3Optimizer\nThis corresponds to increasing the learning rate linearly for the first warmup_steps training steps, and decreasing it thereafter proportionally to the inverse square root of the step number. We usedwarmup_steps = 4000.",
    "content_ltks": "5 3optim thi correspond to increas the learn rate linearli for the first warmup _ step train step and decreas it thereaft proport to the invers squar root of the step number we usedwarmup _ step 4000",
    "content_sm_ltks": "5 3optim thi correspond to increas the learn rate linearli for the first warmup _ step train step and decreas it thereaft proport to the invers squar root of the step number we usedwarmup _ step 4000"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x786 at 0x265D0267370>",
    "page_num_int": [
      7,
      7
    ],
    "position_int": [
      [
        7,
        106,
        503,
        635,
        646
      ],
      [
        7,
        107,
        504,
        656,
        691
      ]
    ],
    "top_int": [
      635,
      656
    ],
    "content_with_weight": "5.4Regularization\nWe employ three types of regularization during training:Residual Dropout We apply dropout [33] to the output of each sub-layer, before it is added to the",
    "content_ltks": "5 4regular we employ three type of regular dure train residu dropout we appli dropout 33 to the output of each sub layer befor it is ad to the",
    "content_sm_ltks": "5 4regular we employ three type of regular dure train residu dropout we appli dropout 33 to the output of each sub layer befor it is ad to the"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x689 at 0x265D0267340>",
    "page_num_int": [
      7,
      7
    ],
    "position_int": [
      [
        7,
        106,
        506,
        635,
        646
      ],
      [
        7,
        105,
        505,
        689,
        724
      ]
    ],
    "top_int": [
      635,
      689
    ],
    "content_with_weight": "5.4Regularization\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and thepositional encodings in both the encoder and decoder stacks. For the base model, we use a rate ofPdrop = 0.1.",
    "content_ltks": "5 4regular sub layer input and normal in addit we appli dropout to the sum of the embed and theposit encod in both the encod and decod stack for the base model we use a rate ofpdrop 01",
    "content_sm_ltks": "5 4regular sub layer input and normal in addit we appli dropout to the sum of the embed and theposit encod in both the encod and decod stack for the base model we use a rate ofpdrop 01"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x810 at 0x265D02672E0>",
    "page_num_int": [
      7,
      8
    ],
    "position_int": [
      [
        7,
        106,
        503,
        635,
        646
      ],
      [
        8,
        107,
        504,
        70,
        93
      ]
    ],
    "top_int": [
      635,
      70
    ],
    "content_with_weight": "5.4Regularization\nTable 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on theEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.",
    "content_ltks": "5 4regular tabl 2 the transform achiev better bleu score than previou state of the art model on theenglish to german and english to french newstest2014 test at a fraction of the train cost",
    "content_sm_ltks": "5 4regular tabl 2 the transform achiev better bleu score than previou state of the art model on theenglish to german and english to french newstest2014 test at a fraction of the train cost"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=262x774 at 0x265D02673A0>",
    "page_num_int": [
      7,
      8
    ],
    "position_int": [
      [
        7,
        106,
        193,
        635,
        646
      ],
      [
        8,
        309,
        396,
        96,
        108
      ]
    ],
    "top_int": [
      635,
      96
    ],
    "content_with_weight": "5.4Regularization\nBLEU",
    "content_ltks": "5 4regular bleu",
    "content_sm_ltks": "5 4regular bleu"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=287x774 at 0x265D0267850>",
    "page_num_int": [
      7,
      8
    ],
    "position_int": [
      [
        7,
        106,
        201,
        635,
        646
      ],
      [
        8,
        381,
        477,
        96,
        108
      ]
    ],
    "top_int": [
      635,
      96
    ],
    "content_with_weight": "5.4Regularization\nTraining Cost (FLOPs)",
    "content_ltks": "5 4regular train cost flop",
    "content_sm_ltks": "5 4regular train cost flop"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=262x775 at 0x265D02677C0>",
    "page_num_int": [
      7,
      8
    ],
    "position_int": [
      [
        7,
        106,
        193,
        635,
        646
      ],
      [
        8,
        134,
        222,
        104,
        116
      ]
    ],
    "top_int": [
      635,
      104
    ],
    "content_with_weight": "5.4Regularization\nModel",
    "content_ltks": "5 4regular model",
    "content_sm_ltks": "5 4regular model"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=262x774 at 0x265D0267820>",
    "page_num_int": [
      7,
      8
    ],
    "position_int": [
      [
        7,
        106,
        193,
        635,
        646
      ],
      [
        8,
        287,
        375,
        112,
        123
      ]
    ],
    "top_int": [
      635,
      112
    ],
    "content_with_weight": "5.4Regularization\nEN-DE",
    "content_ltks": "5 4regular en de",
    "content_sm_ltks": "5 4regular en de"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=262x774 at 0x265D0267730>",
    "page_num_int": [
      7,
      8
    ],
    "position_int": [
      [
        7,
        106,
        193,
        635,
        646
      ],
      [
        8,
        328,
        415,
        112,
        123
      ]
    ],
    "top_int": [
      635,
      112
    ],
    "content_with_weight": "5.4Regularization\nEN-FR",
    "content_ltks": "5 4regular en fr",
    "content_sm_ltks": "5 4regular en fr"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=262x767 at 0x265D0267760>",
    "page_num_int": [
      7,
      8
    ],
    "position_int": [
      [
        7,
        106,
        193,
        635,
        646
      ],
      [
        8,
        386,
        474,
        113,
        122
      ]
    ],
    "top_int": [
      635,
      113
    ],
    "content_with_weight": "5.4Regularization\nEN-DE",
    "content_ltks": "5 4regular en de",
    "content_sm_ltks": "5 4regular en de"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=262x774 at 0x265D0267790>",
    "page_num_int": [
      7,
      8
    ],
    "position_int": [
      [
        7,
        106,
        193,
        635,
        646
      ],
      [
        8,
        439,
        526,
        112,
        123
      ]
    ],
    "top_int": [
      635,
      112
    ],
    "content_with_weight": "5.4Regularization\nEN-FR",
    "content_ltks": "5 4regular en fr",
    "content_sm_ltks": "5 4regular en fr"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=262x775 at 0x265D0267700>",
    "page_num_int": [
      7,
      8
    ],
    "position_int": [
      [
        7,
        106,
        193,
        635,
        646
      ],
      [
        8,
        134,
        222,
        123,
        135
      ]
    ],
    "top_int": [
      635,
      123
    ],
    "content_with_weight": "5.4Regularization\nByteNet [18]",
    "content_ltks": "5 4regular bytenet 18",
    "content_sm_ltks": "5 4regular bytenet 18"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=301x778 at 0x265D02676D0>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        291,
        391,
        123,
        135
      ],
      [
        8,
        135,
        236,
        135,
        147
      ]
    ],
    "top_int": [
      123,
      135
    ],
    "content_with_weight": "23.75\nDeep-Att + PosUnk [39]",
    "content_ltks": "23 75 deep att posunk 39",
    "content_sm_ltks": "23 75 deep att posunk 39"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=222x786 at 0x265D02676A0>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        433,
        507,
        134,
        148
      ],
      [
        8,
        135,
        209,
        147,
        158
      ]
    ],
    "top_int": [
      134,
      147
    ],
    "content_with_weight": "1.0 Â· 1020\nGNMT + RL [38]",
    "content_ltks": "10 1020 gnmt rl 38",
    "content_sm_ltks": "10 1020 gnmt rl 38"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=159x780 at 0x265D02675B0>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        433,
        486,
        145,
        157
      ],
      [
        8,
        135,
        188,
        158,
        170
      ]
    ],
    "top_int": [
      145,
      158
    ],
    "content_with_weight": "1.4 Â·1020\nConvS2S [9]",
    "content_ltks": "1 4 1020 convs2 9",
    "content_sm_ltks": "1 4 1020 convs2 9"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=129x787 at 0x265D0267610>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        432,
        475,
        157,
        172
      ],
      [
        8,
        134,
        177,
        170,
        181
      ]
    ],
    "top_int": [
      157,
      170
    ],
    "content_with_weight": "1.5 Â· 1020\nMoE [32]",
    "content_ltks": "15 1020 moe 32",
    "content_sm_ltks": "15 1020 moe 32"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=432x780 at 0x265D02675E0>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        433,
        577,
        169,
        181
      ],
      [
        8,
        134,
        278,
        182,
        194
      ]
    ],
    "top_int": [
      169,
      182
    ],
    "content_with_weight": "1.2 Â· 1020\nDeep-Att + PosUnk Ensemble [39]",
    "content_ltks": "12 1020 deep att posunk ensembl 39",
    "content_sm_ltks": "12 1020 deep att posunk ensembl 39"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=346x786 at 0x265D0267640>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        432,
        547,
        181,
        195
      ],
      [
        8,
        135,
        251,
        194,
        205
      ]
    ],
    "top_int": [
      181,
      194
    ],
    "content_with_weight": "8.0 Â· 1020\nGNMT + RL Ensemble [38]",
    "content_ltks": "80 1020 gnmt rl ensembl 38",
    "content_sm_ltks": "80 1020 gnmt rl ensembl 38"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=289x786 at 0x265D02674F0>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        432,
        528,
        192,
        207
      ],
      [
        8,
        134,
        230,
        204,
        216
      ]
    ],
    "top_int": [
      192,
      204
    ],
    "content_with_weight": "1.1 Â· 1021\nConvS2S Ensemble [9]",
    "content_ltks": "11 1021 convs2 ensembl 9",
    "content_sm_ltks": "11 1021 convs2 ensembl 9"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=327x779 at 0x265D0267580>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        433,
        542,
        205,
        217
      ],
      [
        8,
        133,
        242,
        217,
        228
      ]
    ],
    "top_int": [
      205,
      217
    ],
    "content_with_weight": "1.2 Â· 1021\nTransformer (base model)",
    "content_ltks": "12 1021 transform base model",
    "content_sm_ltks": "12 1021 transform base model"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=222x780 at 0x265D0267550>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        404,
        478,
        218,
        230
      ],
      [
        8,
        134,
        208,
        229,
        241
      ]
    ],
    "top_int": [
      218,
      229
    ],
    "content_with_weight": "3.3Â· 1018\nTransformer (big)",
    "content_ltks": "33 1018 transform big",
    "content_sm_ltks": "33 1018 transform big"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1194x815 at 0x265D0267430>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        407,
        805,
        228,
        241
      ],
      [
        8,
        106,
        504,
        271,
        294
      ]
    ],
    "top_int": [
      228,
      271
    ],
    "content_with_weight": "2.3Â· 1019\nLabel SmoothingDuring training, we employed label smoothing of value Els = 0.1 [36]. Thishurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.",
    "content_ltks": "23 1019 label smoothingdur train we employ label smooth of valu el 01 36 thishurt perplex a the model learn to be more unsur but improv accuraci and bleu score",
    "content_sm_ltks": "23 1019 label smoothingdur train we employ label smooth of valu el 01 36 thishurt perplex a the model learn to be more unsur but improv accuraci and bleu score"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=172x780 at 0x265D0267520>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        407,
        464,
        228,
        241
      ],
      [
        8,
        106,
        163,
        312,
        324
      ]
    ],
    "top_int": [
      228,
      312
    ],
    "content_with_weight": "2.3Â· 1019\n6Results",
    "content_ltks": "23 1019 6result",
    "content_sm_ltks": "23 1019 6result"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1198x938 at 0x265D02674C0>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        106,
        505,
        337,
        348
      ],
      [
        8,
        106,
        505,
        358,
        424
      ]
    ],
    "top_int": [
      337,
      358
    ],
    "content_with_weight": "6.1Machine Translation\n On the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)in Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0BLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model islisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base modelsurpasses all previously published models and ensembles, at a fraction of the training cost of any ofthe competitive models.",
    "content_ltks": "6 1machin translat on the wmt 2014 english to german translat task the big transform model transform big in tabl 2 outperform the best previous report model includ ensembl by more than 2 0bleu establish a new state of the art bleu score of 28 4 the configur of thi model islist in the bottom line of tabl 3 train took 35 day on 8 p100 gpu even our base modelsurpass all previous publish model and ensembl at a fraction of the train cost of ani ofth competit model",
    "content_sm_ltks": "6 1machin translat on the wmt 2014 english to german translat task the big transform model transform big in tabl 2 outperform the best previous report model includ ensembl by more than 2 0bleu establish a new state of the art bleu score of 28 4 the configur of thi model islist in the bottom line of tabl 3 train took 35 day on 8 p100 gpu even our base modelsurpass all previous publish model and ensembl at a fraction of the train cost of ani ofth competit model"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1198x876 at 0x265D0267490>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        106,
        505,
        337,
        348
      ],
      [
        8,
        106,
        505,
        428,
        473
      ]
    ],
    "top_int": [
      337,
      428
    ],
    "content_with_weight": "6.1Machine Translation\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0, outperforming all of the previously published single models, at less than 1/4 the training cost of theprevious state-of-the-art model. The Transformer (big) model trained for English-to-French useddropout rate Pdrop = 0.1, instead of 0.3.",
    "content_ltks": "6 1machin translat on the wmt 2014 english to french translat task our big model achiev a bleu score of 41 0 outperform all of the previous publish singl model at less than 1 4 the train cost of theprevi state of the art model the transform big model train for english to french useddropout rate pdrop 01 instead of 0 3",
    "content_sm_ltks": "6 1machin translat on the wmt 2014 english to french translat task our big model achiev a bleu score of 41 0 outperform all of the previous publish singl model at less than 1 4 the train cost of theprevi state of the art model the transform big model train for english to french useddropout rate pdrop 01 instead of 0 3"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x904 at 0x265D02673D0>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        106,
        506,
        337,
        348
      ],
      [
        8,
        105,
        505,
        478,
        533
      ]
    ],
    "top_int": [
      337,
      478
    ],
    "content_with_weight": "6.1Machine Translation\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, whichwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. Weused beam search with a beam size of 4 and length penalty Q = 0.6 [38]. These hyperparameterswere chosen after experimentation on the development set. We set the maximum output length duringinference to input length + 50, but terminate early when possible [38].",
    "content_ltks": "6 1machin translat for the base model we use a singl model obtain by averag the last 5 checkpoint whichwer written at 10 minut interv for the big model we averag the last 20 checkpoint weus beam search with a beam size of 4 and length penalti q 0 6 38 these hyperparameterswer chosen after experiment on the develop set we set the maximum output length duringinfer to input length 50 but termin earli when possibl 38",
    "content_sm_ltks": "6 1machin translat for the base model we use a singl model obtain by averag the last 5 checkpoint whichwer written at 10 minut interv for the big model we averag the last 20 checkpoint weus beam search with a beam size of 4 and length penalti q 0 6 38 these hyperparameterswer chosen after experiment on the develop set we set the maximum output length duringinfer to input length 50 but termin earli when possibl 38"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1203x883 at 0x265D02677F0>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        106,
        507,
        337,
        348
      ],
      [
        8,
        104,
        505,
        536,
        584
      ]
    ],
    "top_int": [
      337,
      536
    ],
    "content_with_weight": "6.1Machine Translation\n Table 2 summarizes our results and compares our translation quality and training costs to other modelarchitectures from the literature. We estimate the number of floating point operations used to train amodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained single-precision floating-point capacity of each GPU 5.",
    "content_ltks": "6 1machin translat tabl 2 summar our result and compar our translat qualiti and train cost to other modelarchitectur from the literatur we estim the number of float point oper use to train amodel by multipli the train time the number of gpu use and an estim of the sustain singl precis float point capac of each gpu 5",
    "content_sm_ltks": "6 1machin translat tabl 2 summar our result and compar our translat qualiti and train cost to other modelarchitectur from the literatur we estim the number of float point oper use to train amodel by multipli the train time the number of gpu use and an estim of the sustain singl precis float point capac of each gpu 5"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1203x882 at 0x265D0267670>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        105,
        506,
        596,
        607
      ],
      [
        8,
        104,
        505,
        616,
        663
      ]
    ],
    "top_int": [
      596,
      616
    ],
    "content_with_weight": "6.2Model Variations\n To evaluate the importance of different components of the Transformer, we varied our base modelin different ways, measuring the change in performance on English-to-German translation on thedevelopment set, newstest2013. We used beam search as described in the previous section, but nocheckpoint averaging. We present these results in Table 3.",
    "content_ltks": "6 2model variat to evalu the import of differ compon of the transform we vari our base modelin differ way measur the chang in perform on english to german translat on thedevelop set newstest2013 we use beam search a describ in the previou section but nocheckpoint averag we present these result in tabl 3",
    "content_sm_ltks": "6 2model variat to evalu the import of differ compon of the transform we vari our base modelin differ way measur the chang in perform on english to german translat on thedevelop set newstest2013 we use beam search a describ in the previou section but nocheckpoint averag we present these result in tabl 3"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x755 at 0x265D0267880>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        105,
        505,
        596,
        607
      ],
      [
        8,
        105,
        505,
        667,
        701
      ]
    ],
    "top_int": [
      596,
      667
    ],
    "content_with_weight": "6.2Model Variations\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,keeping the amount of computation constant, as described in Section 3.2.2. While single-headattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.",
    "content_ltks": "6 2model variat in tabl 3 row a we vari the number of attent head and the attent key and valu dimens keep the amount of comput constant a describ in section 32 2 while singl headattent is 0 9 bleu wors than the best set qualiti also drop off with too mani head",
    "content_sm_ltks": "6 2model variat in tabl 3 row a we vari the number of attent head and the attent key and valu dimens keep the amount of comput constant a describ in section 32 2 while singl headattent is 0 9 bleu wors than the best set qualiti also drop off with too mani head"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1001x624 at 0x265D02678B0>",
    "page_num_int": [
      8,
      8
    ],
    "position_int": [
      [
        8,
        105,
        439,
        596,
        607
      ],
      [
        8,
        119,
        453,
        711,
        722
      ]
    ],
    "top_int": [
      596,
      711
    ],
    "content_with_weight": "6.2Model Variations\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.",
    "content_ltks": "6 2model variat 5we use valu of 28 37 60 and 95 tflop for k80 k40 m40 and p100 respect",
    "content_sm_ltks": "6 2model variat 5we use valu of 28 37 60 and 95 tflop for k80 k40 m40 and p100 respect"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1208x877 at 0x265D02678E0>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        508,
        596,
        607
      ],
      [
        9,
        104,
        507,
        69,
        114
      ]
    ],
    "top_int": [
      596,
      69
    ],
    "content_with_weight": "6.2Model Variations\nTable 3: Variations on the Transformer architecture. Unlisted values are identical to those of the basemodel. All metrics are on the English-to-German translation development set, newstest2013. Listed perplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to per-word perplexities.",
    "content_ltks": "6 2model variat tabl 3 variat on the transform architectur unlist valu are ident to those of the basemodel all metric are on the english to german translat develop set newstest2013 list perplex are per wordpiec accord to our byte pair encod and should not be compar to per word perplex",
    "content_sm_ltks": "6 2model variat tabl 3 variat on the transform architectur unlist valu are ident to those of the basemodel all metric are on the english to german translat develop set newstest2013 list perplex are per wordpiec accord to our byte pair encod and should not be compar to per word perplex"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=297x780 at 0x265D02679A0>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        204,
        596,
        607
      ],
      [
        9,
        164,
        263,
        134,
        147
      ]
    ],
    "top_int": [
      596,
      134
    ],
    "content_with_weight": "6.2Model Variations\ndmodel",
    "content_ltks": "6 2model variat dmodel",
    "content_sm_ltks": "6 2model variat dmodel"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=297x768 at 0x265D0267400>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        204,
        596,
        607
      ],
      [
        9,
        369,
        468,
        132,
        141
      ]
    ],
    "top_int": [
      596,
      132
    ],
    "content_with_weight": "6.2Model Variations\ntrain",
    "content_ltks": "6 2model variat train",
    "content_sm_ltks": "6 2model variat train"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=297x770 at 0x265D0267A00>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        204,
        596,
        607
      ],
      [
        9,
        401,
        500,
        129,
        139
      ]
    ],
    "top_int": [
      596,
      129
    ],
    "content_with_weight": "6.2Model Variations\nPPL",
    "content_ltks": "6 2model variat ppl",
    "content_sm_ltks": "6 2model variat ppl"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=297x774 at 0x265D0267A60>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        204,
        596,
        607
      ],
      [
        9,
        206,
        305,
        136,
        147
      ]
    ],
    "top_int": [
      596,
      136
    ],
    "content_with_weight": "6.2Model Variations\ndff",
    "content_ltks": "6 2model variat dff",
    "content_sm_ltks": "6 2model variat dff"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=297x771 at 0x265D0267BB0>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        204,
        596,
        607
      ],
      [
        9,
        257,
        356,
        136,
        146
      ]
    ],
    "top_int": [
      596,
      136
    ],
    "content_with_weight": "6.2Model Variations\ndk",
    "content_ltks": "6 2model variat dk",
    "content_sm_ltks": "6 2model variat dk"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=297x774 at 0x265D0267B50>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        204,
        596,
        607
      ],
      [
        9,
        283,
        382,
        136,
        147
      ]
    ],
    "top_int": [
      596,
      136
    ],
    "content_with_weight": "6.2Model Variations\nd~",
    "content_ltks": "6 2model variat d",
    "content_sm_ltks": "6 2model variat d"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=297x778 at 0x265D0267D00>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        204,
        596,
        607
      ],
      [
        9,
        308,
        407,
        134,
        146
      ]
    ],
    "top_int": [
      596,
      134
    ],
    "content_with_weight": "6.2Model Variations\nPdrop",
    "content_ltks": "6 2model variat pdrop",
    "content_sm_ltks": "6 2model variat pdrop"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=297x776 at 0x265D0267460>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        204,
        596,
        607
      ],
      [
        9,
        433,
        532,
        130,
        142
      ]
    ],
    "top_int": [
      596,
      130
    ],
    "content_with_weight": "6.2Model Variations\nBLEU",
    "content_ltks": "6 2model variat bleu",
    "content_sm_ltks": "6 2model variat bleu"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=297x769 at 0x265D0267A30>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        204,
        596,
        607
      ],
      [
        9,
        472,
        571,
        132,
        142
      ]
    ],
    "top_int": [
      596,
      132
    ],
    "content_with_weight": "6.2Model Variations\nparams",
    "content_ltks": "6 2model variat param",
    "content_sm_ltks": "6 2model variat param"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=297x771 at 0x265D0267D60>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        204,
        596,
        607
      ],
      [
        9,
        343,
        442,
        137,
        147
      ]
    ],
    "top_int": [
      596,
      137
    ],
    "content_with_weight": "6.2Model Variations\nEls",
    "content_ltks": "6 2model variat el",
    "content_sm_ltks": "6 2model variat el"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=297x778 at 0x265D0267DC0>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        204,
        596,
        607
      ],
      [
        9,
        368,
        467,
        142,
        154
      ]
    ],
    "top_int": [
      596,
      142
    ],
    "content_with_weight": "6.2Model Variations\nsteps",
    "content_ltks": "6 2model variat step",
    "content_sm_ltks": "6 2model variat step"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=297x775 at 0x265D0267C10>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        204,
        596,
        607
      ],
      [
        9,
        400,
        499,
        142,
        153
      ]
    ],
    "top_int": [
      596,
      142
    ],
    "content_with_weight": "6.2Model Variations\n(dev)",
    "content_ltks": "6 2model variat dev",
    "content_sm_ltks": "6 2model variat dev"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=297x775 at 0x265D0267F40>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        204,
        596,
        607
      ],
      [
        9,
        436,
        535,
        142,
        153
      ]
    ],
    "top_int": [
      596,
      142
    ],
    "content_with_weight": "6.2Model Variations\n(dev)",
    "content_ltks": "6 2model variat dev",
    "content_sm_ltks": "6 2model variat dev"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=297x778 at 0x265D0266290>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        204,
        596,
        607
      ],
      [
        9,
        475,
        574,
        141,
        153
      ]
    ],
    "top_int": [
      596,
      141
    ],
    "content_with_weight": "6.2Model Variations\nÃ—106",
    "content_ltks": "6 2model variat 106",
    "content_sm_ltks": "6 2model variat 106"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=297x773 at 0x265D0267D90>",
    "page_num_int": [
      8,
      9
    ],
    "position_int": [
      [
        8,
        105,
        204,
        596,
        607
      ],
      [
        9,
        114,
        213,
        156,
        166
      ]
    ],
    "top_int": [
      596,
      156
    ],
    "content_with_weight": "6.2Model Variations\nbase",
    "content_ltks": "6 2model variat base",
    "content_sm_ltks": "6 2model variat base"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=80x772 at 0x265D0266F80>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        342,
        369,
        155,
        165
      ],
      [
        9,
        366,
        393,
        154,
        165
      ]
    ],
    "top_int": [
      155,
      154
    ],
    "content_with_weight": "0.1\n100K",
    "content_ltks": "01 100k",
    "content_sm_ltks": "01 100k"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=60x772 at 0x265D0265DE0>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        439,
        459,
        178,
        188
      ],
      [
        9,
        117,
        137,
        184,
        195
      ]
    ],
    "top_int": [
      178,
      184
    ],
    "content_with_weight": "25.5\n(A)",
    "content_ltks": "25 5a",
    "content_sm_ltks": "25 5a"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=62x777 at 0x265D0278100>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        439,
        459,
        212,
        224
      ],
      [
        9,
        117,
        138,
        218,
        229
      ]
    ],
    "top_int": [
      212,
      218
    ],
    "content_with_weight": "25.1\n(B)",
    "content_ltks": "25 1 b",
    "content_sm_ltks": "25 1 b"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=60x772 at 0x265D0278160>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        439,
        459,
        258,
        268
      ],
      [
        9,
        116,
        136,
        269,
        280
      ]
    ],
    "top_int": [
      258,
      269
    ],
    "content_with_weight": "25.5\n(C)",
    "content_ltks": "25 5 c",
    "content_sm_ltks": "25 5 c"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=64x782 at 0x265D0278250>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        438,
        459,
        324,
        336
      ],
      [
        9,
        115,
        137,
        330,
        342
      ]
    ],
    "top_int": [
      324,
      330
    ],
    "content_with_weight": "25.5\n(D)",
    "content_ltks": "25 5d",
    "content_sm_ltks": "25 5d"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=57x773 at 0x265D02783D0>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        440,
        459,
        347,
        357
      ],
      [
        9,
        117,
        136,
        359,
        371
      ]
    ],
    "top_int": [
      347,
      359
    ],
    "content_with_weight": "25.7\n(E)",
    "content_ltks": "25 7 e",
    "content_sm_ltks": "25 7 e"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=516x773 at 0x265D0278310>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        440,
        612,
        347,
        357
      ],
      [
        9,
        176,
        348,
        359,
        371
      ]
    ],
    "top_int": [
      347,
      359
    ],
    "content_with_weight": "25.7\npositional embedding instead of sinusoids",
    "content_ltks": "25 7 posit embed instead of sinusoid",
    "content_sm_ltks": "25 7 posit embed instead of sinusoid"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=62x782 at 0x265D02782E0>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        439,
        459,
        359,
        371
      ],
      [
        9,
        116,
        137,
        372,
        384
      ]
    ],
    "top_int": [
      359,
      372
    ],
    "content_with_weight": "25.7\nbig",
    "content_ltks": "25 7 big",
    "content_sm_ltks": "25 7 big"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x767 at 0x265D02783A0>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        313,
        337,
        372,
        382
      ],
      [
        9,
        368,
        392,
        373,
        382
      ]
    ],
    "top_int": [
      372,
      373
    ],
    "content_with_weight": "0.3\n300K",
    "content_ltks": "0 3 300k",
    "content_sm_ltks": "0 3 300k"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x812 at 0x265D0278370>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        438,
        838,
        370,
        382
      ],
      [
        9,
        105,
        505,
        401,
        423
      ]
    ],
    "top_int": [
      370,
      401
    ],
    "content_with_weight": "26.4\n Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23of WSJ)",
    "content_ltks": "26 4 tabl 4 the transform gener well to english constitu pars result are on section 23of wsj",
    "content_sm_ltks": "26 4 tabl 4 the transform gener well to english constitu pars result are on section 23of wsj"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=97x779 at 0x265D0278880>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        438,
        470,
        370,
        382
      ],
      [
        9,
        204,
        237,
        425,
        436
      ]
    ],
    "top_int": [
      370,
      425
    ],
    "content_with_weight": "26.4\nParser",
    "content_ltks": "26 4 parser",
    "content_sm_ltks": "26 4 parser"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=124x782 at 0x265D0278850>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        438,
        479,
        370,
        382
      ],
      [
        9,
        332,
        373,
        423,
        435
      ]
    ],
    "top_int": [
      370,
      423
    ],
    "content_with_weight": "26.4\nTraining",
    "content_ltks": "26 4 train",
    "content_sm_ltks": "26 4 train"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=154x779 at 0x265D0278760>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        438,
        489,
        370,
        382
      ],
      [
        9,
        411,
        463,
        425,
        436
      ]
    ],
    "top_int": [
      370,
      425
    ],
    "content_with_weight": "26.4\nWSJ 23 F1",
    "content_ltks": "26 4 wsj 23 f1",
    "content_sm_ltks": "26 4 wsj 23 f1"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=431x780 at 0x265D02787F0>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        438,
        582,
        370,
        382
      ],
      [
        9,
        149,
        292,
        436,
        448
      ]
    ],
    "top_int": [
      370,
      436
    ],
    "content_with_weight": "26.4\nVinyals & Kaiser el al. (2014) [37]",
    "content_ltks": "26 4 vinyal kaiser el al 2014 37",
    "content_sm_ltks": "26 4 vinyal kaiser el al 2014 37"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=309x780 at 0x265D02787C0>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        438,
        541,
        370,
        382
      ],
      [
        9,
        301,
        404,
        436,
        448
      ]
    ],
    "top_int": [
      370,
      436
    ],
    "content_with_weight": "26.4\nWSJ only, discriminative",
    "content_ltks": "26 4 wsj onli discrimin",
    "content_sm_ltks": "26 4 wsj onli discrimin"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=294x777 at 0x265D0278790>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        426,
        524,
        435,
        448
      ],
      [
        9,
        171,
        269,
        448,
        458
      ]
    ],
    "top_int": [
      435,
      448
    ],
    "content_with_weight": "88.3\nPetrov et al. (2006) [29]",
    "content_ltks": "88 3 petrov et al 2006 29",
    "content_sm_ltks": "88 3 petrov et al 2006 29"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=309x780 at 0x265D0278730>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        426,
        529,
        435,
        448
      ],
      [
        9,
        301,
        404,
        447,
        458
      ]
    ],
    "top_int": [
      435,
      447
    ],
    "content_with_weight": "88.3\nWSJ only, discriminative",
    "content_ltks": "88 3 wsj onli discrimin",
    "content_sm_ltks": "88 3 wsj onli discrimin"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=267x770 at 0x265D0278700>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        516,
        448,
        458
      ],
      [
        9,
        176,
        265,
        458,
        469
      ]
    ],
    "top_int": [
      448,
      458
    ],
    "content_with_weight": "90.4\nZhu et al. (2013) [40]",
    "content_ltks": "90 4 zhu et al 2013 40",
    "content_sm_ltks": "90 4 zhu et al 2013 40"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=317x780 at 0x265D02786A0>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        533,
        448,
        458
      ],
      [
        9,
        299,
        405,
        456,
        470
      ]
    ],
    "top_int": [
      448,
      456
    ],
    "content_with_weight": "90.4\nWSJ only, discriminative",
    "content_ltks": "90 4 wsj onli discrimin",
    "content_sm_ltks": "90 4 wsj onli discrimin"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=267x770 at 0x265D02786D0>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        516,
        458,
        468
      ],
      [
        9,
        176,
        265,
        469,
        480
      ]
    ],
    "top_int": [
      458,
      469
    ],
    "content_with_weight": "90.4\nDyer et al. (2016) [8]",
    "content_ltks": "90 4 dyer et al 2016 8",
    "content_sm_ltks": "90 4 dyer et al 2016 8"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=312x770 at 0x265D02785E0>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        531,
        458,
        468
      ],
      [
        9,
        301,
        405,
        469,
        480
      ]
    ],
    "top_int": [
      458,
      469
    ],
    "content_with_weight": "90.4\nWSJ only, discriminative",
    "content_ltks": "90 4 wsj onli discrimin",
    "content_sm_ltks": "90 4 wsj onli discrimin"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=279x773 at 0x265D0278670>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        520,
        469,
        479
      ],
      [
        9,
        174,
        267,
        479,
        491
      ]
    ],
    "top_int": [
      469,
      479
    ],
    "content_with_weight": "91.7\nTransformer (4 layers)",
    "content_ltks": "91 7 transform 4 layer",
    "content_sm_ltks": "91 7 transform 4 layer"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=314x773 at 0x265D0278520>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        532,
        469,
        479
      ],
      [
        9,
        300,
        405,
        478,
        490
      ]
    ],
    "top_int": [
      469,
      478
    ],
    "content_with_weight": "91.7\nWSJ only, discriminative",
    "content_ltks": "91 7 wsj onli discrimin",
    "content_sm_ltks": "91 7 wsj onli discrimin"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=267x770 at 0x265D0278640>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        516,
        480,
        490
      ],
      [
        9,
        176,
        265,
        491,
        502
      ]
    ],
    "top_int": [
      480,
      491
    ],
    "content_with_weight": "91.3\nZhu et al. (2013) [40]",
    "content_ltks": "913 zhu et al 2013 40",
    "content_sm_ltks": "913 zhu et al 2013 40"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=205x773 at 0x265D0278610>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        495,
        480,
        490
      ],
      [
        9,
        318,
        386,
        491,
        503
      ]
    ],
    "top_int": [
      480,
      491
    ],
    "content_with_weight": "91.3\nsemi-supervised",
    "content_ltks": "913 semi supervis",
    "content_sm_ltks": "913 semi supervis"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=359x780 at 0x265D02785B0>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        546,
        491,
        501
      ],
      [
        9,
        160,
        280,
        500,
        514
      ]
    ],
    "top_int": [
      491,
      500
    ],
    "content_with_weight": "91.3\nHuang & Harper (2009) [14]",
    "content_ltks": "913 huang harper 2009 14",
    "content_sm_ltks": "913 huang harper 2009 14"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=207x773 at 0x265D0278550>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        496,
        491,
        501
      ],
      [
        9,
        318,
        387,
        502,
        514
      ]
    ],
    "top_int": [
      491,
      502
    ],
    "content_with_weight": "91.3\nsemi-supervised",
    "content_ltks": "913 semi supervis",
    "content_sm_ltks": "913 semi supervis"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=345x773 at 0x265D02784F0>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        542,
        502,
        512
      ],
      [
        9,
        163,
        278,
        513,
        524
      ]
    ],
    "top_int": [
      502,
      513
    ],
    "content_with_weight": "91.3\nMcClosky et al. (2006) [26]",
    "content_ltks": "913 mccloski et al 2006 26",
    "content_sm_ltks": "913 mccloski et al 2006 26"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=207x773 at 0x265D0278580>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        496,
        502,
        512
      ],
      [
        9,
        318,
        387,
        513,
        524
      ]
    ],
    "top_int": [
      502,
      513
    ],
    "content_with_weight": "91.3\nsemi-supervised",
    "content_ltks": "913 semi supervis",
    "content_sm_ltks": "913 semi supervis"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=424x772 at 0x265D0278460>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        568,
        513,
        523
      ],
      [
        9,
        149,
        291,
        524,
        535
      ]
    ],
    "top_int": [
      513,
      524
    ],
    "content_with_weight": "92.1\nVinyals & Kaiser el al. (2014) [37]",
    "content_ltks": "92 1 vinyal kaiser el al 2014 37",
    "content_sm_ltks": "92 1 vinyal kaiser el al 2014 37"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=207x772 at 0x265D0278490>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        496,
        513,
        523
      ],
      [
        9,
        318,
        387,
        524,
        535
      ]
    ],
    "top_int": [
      513,
      524
    ],
    "content_with_weight": "92.1\nsemi-supervised",
    "content_ltks": "92 1 semi supervis",
    "content_sm_ltks": "92 1 semi supervis"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=284x772 at 0x265D0278400>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        522,
        524,
        533
      ],
      [
        9,
        173,
        267,
        533,
        545
      ]
    ],
    "top_int": [
      524,
      533
    ],
    "content_with_weight": "92.1\nTransformer (4 layers)",
    "content_ltks": "92 1 transform 4 layer",
    "content_sm_ltks": "92 1 transform 4 layer"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=210x772 at 0x265D02784C0>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        497,
        524,
        533
      ],
      [
        9,
        318,
        388,
        534,
        546
      ]
    ],
    "top_int": [
      524,
      534
    ],
    "content_with_weight": "92.1\nsemi-supervised",
    "content_ltks": "92 1 semi supervis",
    "content_sm_ltks": "92 1 semi supervis"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=304x780 at 0x265D0278430>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        528,
        534,
        544
      ],
      [
        9,
        169,
        271,
        544,
        558
      ]
    ],
    "top_int": [
      534,
      544
    ],
    "content_with_weight": "92.7\nLuong et al. (2015) [23]",
    "content_ltks": "927 luong et al 2015 23",
    "content_sm_ltks": "927 luong et al 2015 23"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=130x765 at 0x265D0278820>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        470,
        534,
        544
      ],
      [
        9,
        331,
        374,
        547,
        556
      ]
    ],
    "top_int": [
      534,
      547
    ],
    "content_with_weight": "92.7\nmulti-task",
    "content_ltks": "927 multi task",
    "content_sm_ltks": "927 multi task"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=267x772 at 0x265D02788B0>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        516,
        546,
        556
      ],
      [
        9,
        176,
        265,
        557,
        568
      ]
    ],
    "top_int": [
      546,
      557
    ],
    "content_with_weight": "93.0\nDyer et al. (2016) [8]",
    "content_ltks": "93 0 dyer et al 2016 8",
    "content_sm_ltks": "93 0 dyer et al 2016 8"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=137x775 at 0x265D0278A30>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        473,
        546,
        556
      ],
      [
        9,
        329,
        374,
        557,
        569
      ]
    ],
    "top_int": [
      546,
      557
    ],
    "content_with_weight": "93.0\ngenerative",
    "content_ltks": "93 0 gener",
    "content_sm_ltks": "93 0 gener"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1203x937 at 0x265D02788E0>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        427,
        828,
        557,
        566
      ],
      [
        9,
        104,
        505,
        597,
        664
      ]
    ],
    "top_int": [
      557,
      597
    ],
    "content_with_weight": "93.3\nIn Table 3 rows (B), we observe that reducing the attention key size d hurts model quality. This suggests that determining compatibility is not easy and that a more sophisticated compatibilityfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected, bigger models are better, and dropout is very helpful in avoiding over-ftting. In row (E) we replace oursinusoidal positional encoding with learned positional embeddings [9], and observe nearly identicalresults to the base model.",
    "content_ltks": "93 3 in tabl 3 row b we observ that reduc the attent key size d hurt model qualiti thi suggest that determin compat is not easi and that a more sophist compatibilityfunct than dot product may be benefici we further observ in row c and d that a expect bigger model are better and dropout is veri help in avoid over ftting in row e we replac oursinusoid posit encod with learn posit embed 9 and observ nearli identicalresult to the base model",
    "content_sm_ltks": "93 3 in tabl 3 row b we observ that reduc the attent key size d hurt model qualiti thi suggest that determin compat is not easi and that a more sophist compatibilityfunct than dot product may be benefici we further observ in row c and d that a expect bigger model are better and dropout is veri help in avoid over ftting in row e we replac oursinusoid posit encod with learn posit embed 9 and observ nearli identicalresult to the base model"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1203x660 at 0x265D0278910>",
    "page_num_int": [
      9,
      9
    ],
    "position_int": [
      [
        9,
        106,
        507,
        679,
        691
      ],
      [
        9,
        104,
        505,
        699,
        725
      ]
    ],
    "top_int": [
      679,
      699
    ],
    "content_with_weight": "6.3English Constituency Parsing\n To evaluate if the Transformer can generalize to other tasks we performed experiments on English constituency parsing. This task presents specific challenges: the output is subject to strong structural",
    "content_ltks": "6 3english constitu pars to evalu if the transform can gener to other task we perform experi on english constitu pars thi task present specif challeng the output is subject to strong structur",
    "content_sm_ltks": "6 3english constitu pars to evalu if the transform can gener to other task we perform experi on english constitu pars thi task present specif challeng the output is subject to strong structur"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1195x810 at 0x265D0278A60>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        504,
        679,
        691
      ],
      [
        10,
        106,
        504,
        74,
        96
      ]
    ],
    "top_int": [
      679,
      74
    ],
    "content_with_weight": "6.3English Constituency Parsing\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequencemodels have not been able to attain state-of-the-art results in small-data regimes [37].",
    "content_ltks": "6 3english constitu pars constraint and is significantli longer than the input furthermor rnn sequenc to sequencemodel have not been abl to attain state of the art result in small data regim 37",
    "content_sm_ltks": "6 3english constitu pars constraint and is significantli longer than the input furthermor rnn sequenc to sequencemodel have not been abl to attain state of the art result in small data regim 37"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1195x907 at 0x265D0278A90>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        504,
        679,
        691
      ],
      [
        10,
        106,
        504,
        101,
        156
      ]
    ],
    "top_int": [
      679,
      101
    ],
    "content_with_weight": "6.3English Constituency Parsing\nWe trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of thePenn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,using the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokensfor the semi-supervised setting.",
    "content_ltks": "6 3english constitu pars we train a4 layer transform with dmodel 1024 on the wall street journal wsj portion of thepenn treebank 25 about 40k train sentenc we also train it in a semi supervis set use the larger high confid and berkleypars corpu from with approxim 17m sentenc 37 we use a vocabulari of 16k token for the wsj onli set and a vocabulari of 32k tokensfor the semi supervis set",
    "content_sm_ltks": "6 3english constitu pars we train a4 layer transform with dmodel 1024 on the wall street journal wsj portion of thepenn treebank 25 about 40k train sentenc we also train it in a semi supervis set use the larger high confid and berkleypars corpu from with approxim 17m sentenc 37 we use a vocabulari of 16k token for the wsj onli set and a vocabulari of 32k tokensfor the semi supervis set"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x909 at 0x265D0278B80>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        506,
        679,
        691
      ],
      [
        10,
        105,
        505,
        161,
        217
      ]
    ],
    "top_int": [
      679,
      161
    ],
    "content_with_weight": "6.3English Constituency Parsing\nWe performed only a small number of experiments to select the dropout, both attention and residual(section 5.4), learning rates and beam size on the Section 22 development set, all other parametersremained unchanged from the English-to-German base translation model. During inference, weincreased the maximum output length to input length + 300. We used a beam size of 21 and Q = 0.3for both WSJ only and the semi-supervised setting.",
    "content_ltks": "6 3english constitu pars we perform onli a small number of experi to select the dropout both attent and residu section 54 learn rate and beam size on the section 22 develop set all other parametersremain unchang from the english to german base translat model dure infer weincreas the maximum output length to input length 300 we use a beam size of 21 and q 0 3for both wsj onli and the semi supervis set",
    "content_sm_ltks": "6 3english constitu pars we perform onli a small number of experi to select the dropout both attent and residu section 54 learn rate and beam size on the section 22 develop set all other parametersremain unchang from the english to german base translat model dure infer weincreas the maximum output length to input length 300 we use a beam size of 21 and q 0 3for both wsj onli and the semi supervis set"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1195x842 at 0x265D02789D0>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        504,
        679,
        691
      ],
      [
        10,
        106,
        504,
        221,
        254
      ]
    ],
    "top_int": [
      679,
      221
    ],
    "content_with_weight": "6.3English Constituency Parsing\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-prisingly well, yielding better results than all previously reported models with the exception of theRecurrent Neural Network Grammar [8].",
    "content_ltks": "6 3english constitu pars our result in tabl 4 show that despit the lack of task specif tune our model perform sur prisingli well yield better result than all previous report model with the except of therecurr neural network grammar 8",
    "content_sm_ltks": "6 3english constitu pars our result in tabl 4 show that despit the lack of task specif tune our model perform sur prisingli well yield better result than all previous report model with the except of therecurr neural network grammar 8"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1198x815 at 0x265D0278BE0>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        505,
        679,
        691
      ],
      [
        10,
        106,
        505,
        259,
        283
      ]
    ],
    "top_int": [
      679,
      259
    ],
    "content_with_weight": "6.3English Constituency Parsing\nIn contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-Parser [29] even when training only on the WSJ training set of 40K sentences.",
    "content_ltks": "6 3english constitu pars in contrast to rnn sequenc to sequenc model 37 the transform outperform the berkeley parser 29 even when train onli on the wsj train set of 40k sentenc",
    "content_sm_ltks": "6 3english constitu pars in contrast to rnn sequenc to sequenc model 37 the transform outperform the berkeley parser 29 even when train onli on the wsj train set of 40k sentenc"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=452x778 at 0x265D0278C10>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        257,
        679,
        691
      ],
      [
        10,
        106,
        257,
        297,
        309
      ]
    ],
    "top_int": [
      679,
      297
    ],
    "content_with_weight": "6.3English Constituency Parsing\n7Conclusion",
    "content_ltks": "6 3english constitu pars 7conclus",
    "content_sm_ltks": "6 3english constitu pars 7conclus"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x842 at 0x265D0278C40>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        10,
        107,
        504,
        321,
        354
      ]
    ],
    "top_int": [
      679,
      321
    ],
    "content_with_weight": "6.3English Constituency Parsing\nIn this work, we presented the Transformer, the first sequence transduction model based entirely onattention, replacing the recurrent layers most commonly used in encoder-decoder architectures withmulti-headed self-attention.",
    "content_ltks": "6 3english constitu pars in thi work we present the transform the first sequenc transduct model base entir onattent replac the recurr layer most commonli use in encod decod architectur withmulti head self attent",
    "content_sm_ltks": "6 3english constitu pars in thi work we present the transform the first sequenc transduct model base entir onattent replac the recurr layer most commonli use in encod decod architectur withmulti head self attent"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x879 at 0x265D0278D30>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        10,
        107,
        504,
        359,
        405
      ]
    ],
    "top_int": [
      679,
      359
    ],
    "content_with_weight": "6.3English Constituency Parsing\nFor translation tasks, the Transformer can be trained significantly faster than architectures basedon recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014English-to-French translation tasks, we achieve a new state of the art. In the former task our bestmodel outperforms even all previously reported ensembles.",
    "content_ltks": "6 3english constitu pars for translat task the transform can be train significantli faster than architectur basedon recurr or convolut layer on both wmt 2014 english to german and wmt 2014english to french translat task we achiev a new state of the art in the former task our bestmodel outperform even all previous report ensembl",
    "content_sm_ltks": "6 3english constitu pars for translat task the transform can be train significantli faster than architectur basedon recurr or convolut layer on both wmt 2014 english to german and wmt 2014english to french translat task we achiev a new state of the art in the former task our bestmodel outperform even all previous report ensembl"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1203x876 at 0x265D0278D90>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        507,
        679,
        691
      ],
      [
        10,
        104,
        505,
        409,
        453
      ]
    ],
    "top_int": [
      679,
      409
    ],
    "content_with_weight": "6.3English Constituency Parsing\nWe are excited about the future of attention-based models and plan to apply them to other tasks. Weplan to extend the Transformer to problems involving input and output modalities other than text and to investigate local, restricted attention mechanisms to effciently handle large inputs and outputssuch as images, audio and video. Making generation less sequential is another research goals of ours.",
    "content_ltks": "6 3english constitu pars we are excit about the futur of attent base model and plan to appli them to other task weplan to extend the transform to problem involv input and output modal other than text and to investig local restrict attent mechan to effcient handl larg input and outputssuch a imag audio and video make gener less sequenti is anoth research goal of our",
    "content_sm_ltks": "6 3english constitu pars we are excit about the futur of attent base model and plan to appli them to other task weplan to extend the transform to problem involv input and output modal other than text and to investig local restrict attent mechan to effcient handl larg input and outputssuch a imag audio and video make gener less sequenti is anoth research goal of our"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1187x807 at 0x265D0278DC0>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        502,
        679,
        691
      ],
      [
        10,
        107,
        503,
        458,
        480
      ]
    ],
    "top_int": [
      679,
      458
    ],
    "content_with_weight": "6.3English Constituency Parsing\nThe code we used to train and evaluate our models is available at https://github.com/tensorflow/tensor2tensor.",
    "content_ltks": "6 3english constitu pars the code we use to train and evalu our model is avail at http github com tensorflow tensor2tensor",
    "content_sm_ltks": "6 3english constitu pars the code we use to train and evalu our model is avail at http github com tensorflow tensor2tensor"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1190x810 at 0x265D0278DF0>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        10,
        107,
        504,
        491,
        514
      ]
    ],
    "top_int": [
      679,
      491
    ],
    "content_with_weight": "6.3English Constituency Parsing\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitfulcomments, corrections and inspiration.",
    "content_ltks": "6 3english constitu pars acknowledg we are grate to nal kalchbrenn and stephan gouw for their fruitfulcom correct and inspir",
    "content_sm_ltks": "6 3english constitu pars acknowledg we are grate to nal kalchbrenn and stephan gouw for their fruitfulcom correct and inspir"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=452x778 at 0x265D0278EE0>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        257,
        679,
        691
      ],
      [
        10,
        106,
        257,
        528,
        540
      ]
    ],
    "top_int": [
      679,
      528
    ],
    "content_with_weight": "6.3English Constituency Parsing\nReferences",
    "content_ltks": "6 3english constitu pars refer",
    "content_sm_ltks": "6 3english constitu pars refer"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1185x815 at 0x265D0278F40>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        501,
        679,
        691
      ],
      [
        10,
        110,
        505,
        545,
        569
      ]
    ],
    "top_int": [
      679,
      545
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[1]  Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprintarXiv:1607.06450, 2016.",
    "content_ltks": "6 3english constitu pars 1 jimmi lei ba jami ryan kiro and geoffrey e hinton layer normal arxiv preprintarxiv 1607 06450 2016",
    "content_sm_ltks": "6 3english constitu pars 1 jimmi lei ba jami ryan kiro and geoffrey e hinton layer normal arxiv preprintarxiv 1607 06450 2016"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1175x815 at 0x265D0278FA0>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        498,
        679,
        691
      ],
      [
        10,
        111,
        503,
        575,
        599
      ]
    ],
    "top_int": [
      679,
      575
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[2]  Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointlylearning to align and translate. CoRR, abs/1409.0473, 2014.",
    "content_ltks": "6 3english constitu pars 2 dzmitri bahdanau kyunghyun cho and yoshua bengio neural machin translat by jointlylearn to align and translat corr ab 1409 0473 2014",
    "content_sm_ltks": "6 3english constitu pars 2 dzmitri bahdanau kyunghyun cho and yoshua bengio neural machin translat by jointlylearn to align and translat corr ab 1409 0473 2014"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1175x810 at 0x265D0278F70>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        498,
        679,
        691
      ],
      [
        10,
        113,
        504,
        604,
        627
      ]
    ],
    "top_int": [
      679,
      604
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[3]  Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neuralmachine translation architectures. CoRR, abs/1703.03906, 2017.",
    "content_ltks": "6 3english constitu pars 3 denni britz anna goldi minh thang luong and quoc v le massiv explor of neuralmachin translat architectur corr ab 1703 03906 2017",
    "content_sm_ltks": "6 3english constitu pars 3 denni britz anna goldi minh thang luong and quoc v le massiv explor of neuralmachin translat architectur corr ab 1703 03906 2017"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1175x810 at 0x265D0279090>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        498,
        679,
        691
      ],
      [
        10,
        113,
        504,
        634,
        656
      ]
    ],
    "top_int": [
      679,
      634
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machinereading. arXiv preprint arXiv:1601.06733, 2016.",
    "content_ltks": "6 3english constitu pars 4 jianpeng cheng li dong and mirella lapata long short term memori network for machineread arxiv preprint arxiv 1601 06733 2016",
    "content_sm_ltks": "6 3english constitu pars 4 jianpeng cheng li dong and mirella lapata long short term memori network for machineread arxiv preprint arxiv 1601 06733 2016"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1180x772 at 0x265D02790F0>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        499,
        679,
        691
      ],
      [
        10,
        112,
        505,
        662,
        695
      ]
    ],
    "top_int": [
      679,
      662
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[5]  Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statisticalmachine translation. CoRR, abs/1406.1078, 2014.",
    "content_ltks": "6 3english constitu pars 5 kyunghyun cho bart van merrienbo caglar gulcehr fethi bougar holger schwenk and yoshua bengio learn phrase represent use rnn encod decod for statisticalmachin translat corr ab 1406 1078 2014",
    "content_sm_ltks": "6 3english constitu pars 5 kyunghyun cho bart van merrienbo caglar gulcehr fethi bougar holger schwenk and yoshua bengio learn phrase represent use rnn encod decod for statisticalmachin translat corr ab 1406 1078 2014"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1180x660 at 0x265D0279120>",
    "page_num_int": [
      9,
      10
    ],
    "position_int": [
      [
        9,
        106,
        499,
        679,
        691
      ],
      [
        10,
        111,
        504,
        699,
        725
      ]
    ],
    "top_int": [
      679,
      699
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[6]  Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXivpreprint arXiv:1610.02357, 2016.",
    "content_ltks": "6 3english constitu pars 6 francoi chollet xception deep learn with depthwis separ convolut arxivpreprint arxiv 1610 02357 2016",
    "content_sm_ltks": "6 3english constitu pars 6 francoi chollet xception deep learn with depthwis separ convolut arxivpreprint arxiv 1610 02357 2016"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1185x820 at 0x265D0279150>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        501,
        679,
        691
      ],
      [
        11,
        110,
        505,
        73,
        99
      ]
    ],
    "top_int": [
      679,
      73
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[7]  Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluationof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.",
    "content_ltks": "6 3english constitu pars 7 junyoung chung caglar gulcehr kyunghyun cho and yoshua bengio empir evaluationof gate recurr neural network on sequenc model corr ab 1412 3555 2014",
    "content_sm_ltks": "6 3english constitu pars 7 junyoung chung caglar gulcehr kyunghyun cho and yoshua bengio empir evaluationof gate recurr neural network on sequenc model corr ab 1412 3555 2014"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1173x807 at 0x265D0279240>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        497,
        679,
        691
      ],
      [
        11,
        113,
        504,
        105,
        127
      ]
    ],
    "top_int": [
      679,
      105
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[8]  Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neuralnetwork grammars. In Proc. of NAACL, 2016.",
    "content_ltks": "6 3english constitu pars 8 chri dyer adhiguna kuncoro miguel ballestero and noah a smith recurr neuralnetwork grammar in proc of naacl 2016",
    "content_sm_ltks": "6 3english constitu pars 8 chri dyer adhiguna kuncoro miguel ballestero and noah a smith recurr neuralnetwork grammar in proc of naacl 2016"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1175x815 at 0x265D02792A0>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        498,
        679,
        691
      ],
      [
        11,
        113,
        504,
        136,
        160
      ]
    ],
    "top_int": [
      679,
      136
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[9]  Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-tional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.",
    "content_ltks": "6 3english constitu pars 9 jona gehr michael auli david grangier deni yarat and yann n dauphin convolu tional sequenc to sequenc learn arxiv preprint arxiv 1705 03122v2 2017",
    "content_sm_ltks": "6 3english constitu pars 9 jona gehr michael auli david grangier deni yarat and yann n dauphin convolu tional sequenc to sequenc learn arxiv preprint arxiv 1705 03122v2 2017"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=452x776 at 0x265D02793C0>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        257,
        679,
        691
      ],
      [
        11,
        107,
        258,
        167,
        178
      ]
    ],
    "top_int": [
      679,
      167
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[10] Alex  Graves.",
    "content_ltks": "6 3english constitu pars 10 alex graf",
    "content_sm_ltks": "6 3english constitu pars 10 alex graf"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1128x815 at 0x265D02792D0>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        482,
        679,
        691
      ],
      [
        11,
        129,
        505,
        165,
        189
      ]
    ],
    "top_int": [
      679,
      165
    ],
    "content_with_weight": "6.3English Constituency Parsing\ns.- Generating sequences with recurrent neural networks.  arXiv preprintarXiv:1308.0850,2013.",
    "content_ltks": "6 3english constitu pars s gener sequenc with recurr neural network arxiv preprintarxiv 1308 0850 2013",
    "content_sm_ltks": "6 3english constitu pars s gener sequenc with recurr neural network arxiv preprintarxiv 1308 0850 2013"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1195x844 at 0x265D0279390>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        504,
        679,
        691
      ],
      [
        11,
        107,
        505,
        198,
        231
      ]
    ],
    "top_int": [
      679,
      198
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-age recognition. In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition, pages 770-778, 2016.",
    "content_ltks": "6 3english constitu pars 11 kaim he xiangyu zhang shaoq ren and jian sun deep residu learn for im age recognit in proceed of the ieee confer on comput vision and patternrecognit page 770 778 2016",
    "content_sm_ltks": "6 3english constitu pars 11 kaim he xiangyu zhang shaoq ren and jian sun deep residu learn for im age recognit in proceed of the ieee confer on comput vision and patternrecognit page 770 778 2016"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1190x812 at 0x265D027BCD0>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        11,
        108,
        504,
        239,
        262
      ]
    ],
    "top_int": [
      679,
      239
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jurgen Schmidhuber. Gradient fow inrecurrent nets: the difficulty of learning long-term dependencies, 2001.",
    "content_ltks": "6 3english constitu pars 12 sepp hochreit yoshua bengio paolo frasconi and jurgen schmidhub gradient fow inrecurr net the difficulti of learn long term depend 2001",
    "content_sm_ltks": "6 3english constitu pars 12 sepp hochreit yoshua bengio paolo frasconi and jurgen schmidhub gradient fow inrecurr net the difficulti of learn long term depend 2001"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1195x810 at 0x265D027B010>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        504,
        679,
        691
      ],
      [
        11,
        107,
        505,
        269,
        292
      ]
    ],
    "top_int": [
      679,
      269
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[13] Sepp Hochreiter and Juirgen Schmidhuber. Long short-term memory.  Neural computation,9(8):1735-1780, 1997.",
    "content_ltks": "6 3english constitu pars 13 sepp hochreit and juirgen schmidhub long short term memori neural comput 98 1735 1780 1997",
    "content_sm_ltks": "6 3english constitu pars 13 sepp hochreit and juirgen schmidhub long short term memori neural comput 98 1735 1780 1997"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1195x849 at 0x265D027B070>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        504,
        679,
        691
      ],
      [
        11,
        106,
        504,
        300,
        335
      ]
    ],
    "top_int": [
      679,
      300
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotationsacross languages. In Proceedings of the 2o09 Conference on Empirical Methods in NaturalLanguage Processing, pages 832-841. ACL, August 2009.",
    "content_ltks": "6 3english constitu pars 14 zhongqiang huang and mari harper self train pcfg grammar with latent annotationsacross languag in proceed of the 2o09 confer on empir method in naturallanguag process page 832 841 acl august 2009",
    "content_sm_ltks": "6 3english constitu pars 14 zhongqiang huang and mari harper self train pcfg grammar with latent annotationsacross languag in proceed of the 2o09 confer on empir method in naturallanguag process page 832 841 acl august 2009"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x814 at 0x265D027B0D0>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        11,
        107,
        504,
        341,
        365
      ]
    ],
    "top_int": [
      679,
      341
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploringthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.",
    "content_ltks": "6 3english constitu pars 15 rafal jozefowicz oriol vinyal mike schuster noam shazeer and yonghui wu exploringth limit of languag model arxiv preprint arxiv 1602 02410 2016",
    "content_sm_ltks": "6 3english constitu pars 15 rafal jozefowicz oriol vinyal mike schuster noam shazeer and yonghui wu exploringth limit of languag model arxiv preprint arxiv 1602 02410 2016"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x813 at 0x265D027BFD0>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        506,
        679,
        691
      ],
      [
        11,
        105,
        505,
        372,
        395
      ]
    ],
    "top_int": [
      679,
      372
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[16]  Lukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in NeuralInformation Processing Systems, (NIPS), 2016.",
    "content_ltks": "6 3english constitu pars 16 lukasz kaiser and sami bengio can activ memori replac attent in advanc in neuralinform process system nip 2016",
    "content_sm_ltks": "6 3english constitu pars 16 lukasz kaiser and sami bengio can activ memori replac attent in advanc in neuralinform process system nip 2016"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x810 at 0x265D027BAF0>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        11,
        107,
        504,
        404,
        426
      ]
    ],
    "top_int": [
      679,
      404
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[17] Lukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conferenceon Learning Representations (ICLR), 2016.",
    "content_ltks": "6 3english constitu pars 17 lukasz kaiser and ilya sutskev neural gpu learn algorithm in intern conferenceon learn represent iclr 2016",
    "content_sm_ltks": "6 3english constitu pars 17 lukasz kaiser and ilya sutskev neural gpu learn algorithm in intern conferenceon learn represent iclr 2016"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1193x837 at 0x265D027BFA0>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        504,
        679,
        691
      ],
      [
        11,
        108,
        505,
        434,
        466
      ]
    ],
    "top_int": [
      679,
      434
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-ray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv: 1610. 10099v2,2017.",
    "content_ltks": "6 3english constitu pars 18 nal kalchbrenn lass espeholt karen simonyan aaron van den oord alex graf and ko ray kavukcuoglu neural machin translat in linear time arxiv preprint arxiv 1610 10099v2 2017",
    "content_sm_ltks": "6 3english constitu pars 18 nal kalchbrenn lass espeholt karen simonyan aaron van den oord alex graf and ko ray kavukcuoglu neural machin translat in linear time arxiv preprint arxiv 1610 10099v2 2017"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1193x777 at 0x265D027B0A0>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        504,
        679,
        691
      ],
      [
        11,
        106,
        504,
        475,
        486
      ]
    ],
    "top_int": [
      679,
      475
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.",
    "content_ltks": "6 3english constitu pars 19 yoon kim carl denton luong hoang and alexand m rush structur attent network",
    "content_sm_ltks": "6 3english constitu pars 19 yoon kim carl denton luong hoang and alexand m rush structur attent network"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=771x775 at 0x265D027BF70>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        363,
        679,
        691
      ],
      [
        11,
        129,
        386,
        486,
        497
      ]
    ],
    "top_int": [
      679,
      486
    ],
    "content_with_weight": "6.3English Constituency Parsing\nIn International Conference on Learning Representations, 2017.",
    "content_ltks": "6 3english constitu pars in intern confer on learn represent 2017",
    "content_sm_ltks": "6 3english constitu pars in intern confer on learn represent 2017"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1190x775 at 0x265D027BAC0>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        11,
        108,
        504,
        507,
        518
      ]
    ],
    "top_int": [
      679,
      507
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.",
    "content_ltks": "6 3english constitu pars 20 diederik kingma and jimmi ba adam a method for stochast optim in iclr 2015",
    "content_sm_ltks": "6 3english constitu pars 20 diederik kingma and jimmi ba adam a method for stochast optim in iclr 2015"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1190x810 at 0x265D027BA90>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        11,
        108,
        504,
        526,
        548
      ]
    ],
    "top_int": [
      679,
      526
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[21]  Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprintarXiv:1703.10722, 2017.",
    "content_ltks": "6 3english constitu pars 21 oleksii kuchaiev and bori ginsburg factor trick for lstm network arxiv preprintarxiv 1703 10722 2017",
    "content_sm_ltks": "6 3english constitu pars 21 oleksii kuchaiev and bori ginsburg factor trick for lstm network arxiv preprintarxiv 1703 10722 2017"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x845 at 0x265D027BA30>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        11,
        107,
        504,
        556,
        590
      ]
    ],
    "top_int": [
      679,
      556
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, BowenZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprintarXiv:1703.03130, 2017.",
    "content_ltks": "6 3english constitu pars 22 zhouhan lin minwei feng cicero nogueira do santo mo yu bing xiang bowenzh and yoshua bengio a structur self attent sentenc embed arxiv preprintarxiv 1703 03130 2017",
    "content_sm_ltks": "6 3english constitu pars 22 zhouhan lin minwei feng cicero nogueira do santo mo yu bing xiang bowenzh and yoshua bengio a structur self attent sentenc embed arxiv preprintarxiv 1703 03130 2017"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1190x812 at 0x265D027B640>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        11,
        108,
        504,
        599,
        622
      ]
    ],
    "top_int": [
      679,
      599
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[23] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-tasksequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.",
    "content_ltks": "6 3english constitu pars 23 minh thang luong quoc v le ilya sutskev oriol vinyal and lukasz kaiser multi tasksequ to sequenc learn arxiv preprint arxiv 1511 06114 2015",
    "content_sm_ltks": "6 3english constitu pars 23 minh thang luong quoc v le ilya sutskev oriol vinyal and lukasz kaiser multi tasksequ to sequenc learn arxiv preprint arxiv 1511 06114 2015"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1190x813 at 0x265D027B9D0>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        11,
        108,
        504,
        629,
        652
      ]
    ],
    "top_int": [
      679,
      629
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[24]  Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-based neural machine translation. arXiv preprint arXiv: 1508.04025, 2015.",
    "content_ltks": "6 3english constitu pars 24 minh thang luong hieu pham and christoph d man effect approach to attent base neural machin translat arxiv preprint arxiv 1508 04025 2015",
    "content_sm_ltks": "6 3english constitu pars 24 minh thang luong hieu pham and christoph d man effect approach to attent base neural machin translat arxiv preprint arxiv 1508 04025 2015"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1190x777 at 0x265D027B850>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        11,
        108,
        504,
        660,
        683
      ]
    ],
    "top_int": [
      679,
      660
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotatedcorpus of english: The penn treebank. Computational linguistics, 19(2):313-330, 1993",
    "content_ltks": "6 3english constitu pars 25 mitchel p marcu mari ann marcinkiewicz and beatric santorini build a larg annotatedcorpu of english the penn treebank comput linguist 19 2 313 330 1993",
    "content_sm_ltks": "6 3english constitu pars 25 mitchel p marcu mari ann marcinkiewicz and beatric santorini build a larg annotatedcorpu of english the penn treebank comput linguist 19 2 313 330 1993"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1190x685 at 0x265D027BA60>",
    "page_num_int": [
      9,
      11
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        11,
        108,
        504,
        691,
        725
      ]
    ],
    "top_int": [
      679,
      691
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[26]  David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. InProceedings of the Human Language Technology Conference of the NAACL, Main Conference,pages 152-159. ACL, June 2006.",
    "content_ltks": "6 3english constitu pars 26 david mccloski eugen charniak and mark johnson effect self train for pars inproceed of the human languag technolog confer of the naacl main confer page 152 159 acl june 2006",
    "content_sm_ltks": "6 3english constitu pars 26 david mccloski eugen charniak and mark johnson effect self train for pars inproceed of the human languag technolog confer of the naacl main confer page 152 159 acl june 2006"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x810 at 0x265D027B610>",
    "page_num_int": [
      9,
      12
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        12,
        107,
        504,
        74,
        96
      ]
    ],
    "top_int": [
      679,
      74
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[27]  Ankur Parikh, Oscar Tackstrom, Dipanjan Das, and Jakob Uszkoreit. A decomposable attentionmodel. In Empirical Methods in Natural Language Processing, 2016.",
    "content_ltks": "6 3english constitu pars 27 ankur parikh oscar tackstrom dipanjan da and jakob uszkoreit a decompos attentionmodel in empir method in natur languag process 2016",
    "content_sm_ltks": "6 3english constitu pars 27 ankur parikh oscar tackstrom dipanjan da and jakob uszkoreit a decompos attentionmodel in empir method in natur languag process 2016"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1195x814 at 0x265D027B580>",
    "page_num_int": [
      9,
      12
    ],
    "position_int": [
      [
        9,
        106,
        504,
        679,
        691
      ],
      [
        12,
        107,
        505,
        114,
        137
      ]
    ],
    "top_int": [
      679,
      114
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[28]  Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractivesummarization. arXiv preprint arXiv:1705.04304, 2017.",
    "content_ltks": "6 3english constitu pars 28 romain paulu caim xiong and richard socher a deep reinforc model for abstractivesummar arxiv preprint arxiv 1705 04304 2017",
    "content_sm_ltks": "6 3english constitu pars 28 romain paulu caim xiong and richard socher a deep reinforc model for abstractivesummar arxiv preprint arxiv 1705 04304 2017"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x872 at 0x265D027BA00>",
    "page_num_int": [
      9,
      12
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        12,
        107,
        504,
        155,
        198
      ]
    ],
    "top_int": [
      679,
      155
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,and interpretable tree annotation. In Proceedings of the 21st International Conference onComputational Linguistics and 44th Annual Meeting of the ACL, pages 433-440. ACL, July2006.",
    "content_ltks": "6 3english constitu pars 29 slav petrov leon barrett romain thibaux and dan klein learn accur compact and interpret tree annot in proceed of the 21st intern confer oncomput linguist and 44th annual meet of the acl page 433 440 acl july2006",
    "content_sm_ltks": "6 3english constitu pars 29 slav petrov leon barrett romain thibaux and dan klein learn accur compact and interpret tree annot in proceed of the 21st intern confer oncomput linguist and 44th annual meet of the acl page 433 440 acl july2006"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1195x815 at 0x265D027B5E0>",
    "page_num_int": [
      9,
      12
    ],
    "position_int": [
      [
        9,
        106,
        504,
        679,
        691
      ],
      [
        12,
        106,
        504,
        217,
        241
      ]
    ],
    "top_int": [
      679,
      217
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[30]  Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXivpreprint arXiv:1608.05859, 2016.",
    "content_ltks": "6 3english constitu pars 30 ofir press and lior wolf use the output embed to improv languag model arxivpreprint arxiv 1608 05859 2016",
    "content_sm_ltks": "6 3english constitu pars 30 ofir press and lior wolf use the output embed to improv languag model arxivpreprint arxiv 1608 05859 2016"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x812 at 0x265D027B670>",
    "page_num_int": [
      9,
      12
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        12,
        107,
        504,
        258,
        281
      ]
    ],
    "top_int": [
      679,
      258
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare wordswith subword units. arXiv preprint arXiv:1508.07909, 2015.",
    "content_ltks": "6 3english constitu pars 31 rico sennrich barri haddow and alexandra birch neural machin translat of rare wordswith subword unit arxiv preprint arxiv 1508 07909 2015",
    "content_sm_ltks": "6 3english constitu pars 31 rico sennrich barri haddow and alexandra birch neural machin translat of rare wordswith subword unit arxiv preprint arxiv 1508 07909 2015"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1198x847 at 0x265D0267F70>",
    "page_num_int": [
      9,
      12
    ],
    "position_int": [
      [
        9,
        106,
        505,
        679,
        691
      ],
      [
        12,
        106,
        505,
        297,
        332
      ]
    ],
    "top_int": [
      679,
      297
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-expertslayer. arXiv preprint arXiv:1701.06538, 2017.",
    "content_ltks": "6 3english constitu pars 32 noam shazeer azalia mirhoseini krzysztof maziarz andi davi quoc le geoffrey hinton and jeff dean outrag larg neural network the spars gate mixtur of expertslay arxiv preprint arxiv 1701 06538 2017",
    "content_sm_ltks": "6 3english constitu pars 32 noam shazeer azalia mirhoseini krzysztof maziarz andi davi quoc le geoffrey hinton and jeff dean outrag larg neural network the spars gate mixtur of expertslay arxiv preprint arxiv 1701 06538 2017"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x847 at 0x265D0266260>",
    "page_num_int": [
      9,
      12
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        12,
        107,
        504,
        349,
        383
      ]
    ],
    "top_int": [
      679,
      349
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-nov. Dropout: a simple way to prevent neural networks from overfitting. Journal of MachineLearning Research, 15(1):1929-1958, 2014.",
    "content_ltks": "6 3english constitu pars 33 nitish srivastava geoffrey e hinton alex krizhevski ilya sutskev and ruslan salakhutdi nov dropout a simpl way to prevent neural network from overfit journal of machinelearn research 15 1 1929 1958 2014",
    "content_sm_ltks": "6 3english constitu pars 33 nitish srivastava geoffrey e hinton alex krizhevski ilya sutskev and ruslan salakhutdi nov dropout a simpl way to prevent neural network from overfit journal of machinelearn research 15 1 1929 1958 2014"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1195x872 at 0x265D0265840>",
    "page_num_int": [
      9,
      12
    ],
    "position_int": [
      [
        9,
        106,
        504,
        679,
        691
      ],
      [
        12,
        107,
        505,
        401,
        444
      ]
    ],
    "top_int": [
      679,
      401
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memorynetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,Advances in Neural Information Processing Systems 28, pages 2440-2448. Curran Associates,Inc.,2015.",
    "content_ltks": "6 3english constitu pars 34 sainbayar sukhbaatar arthur szlam jason weston and rob fergu end to end memorynetwork in c cort n d lawrenc d d lee m sugiyama and r garnett editor advanc in neural inform process system 28 page 2440 2448 curran associ inc 2015",
    "content_sm_ltks": "6 3english constitu pars 34 sainbayar sukhbaatar arthur szlam jason weston and rob fergu end to end memorynetwork in c cort n d lawrenc d d lee m sugiyama and r garnett editor advanc in neural inform process system 28 page 2440 2448 curran associ inc 2015"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1190x813 at 0x265D0267EB0>",
    "page_num_int": [
      9,
      12
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        12,
        108,
        504,
        464,
        487
      ]
    ],
    "top_int": [
      679,
      464
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neuralnetworks. In Advances in Neural Information Processing Systems, pages 3104-3112, 2014.",
    "content_ltks": "6 3english constitu pars 35 ilya sutskev oriol vinyal and quoc vv le sequenc to sequenc learn with neuralnetwork in advanc in neural inform process system page 3104 3112 2014",
    "content_sm_ltks": "6 3english constitu pars 35 ilya sutskev oriol vinyal and quoc vv le sequenc to sequenc learn with neuralnetwork in advanc in neural inform process system page 3104 3112 2014"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x777 at 0x265D0267F10>",
    "page_num_int": [
      9,
      12
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        12,
        107,
        504,
        505,
        516
      ]
    ],
    "top_int": [
      679,
      505
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.",
    "content_ltks": "6 3english constitu pars 36 christian szegedi vincent vanhouck sergey ioff jonathon shlen and zbigniew wojna",
    "content_sm_ltks": "6 3english constitu pars 36 christian szegedi vincent vanhouck sergey ioff jonathon shlen and zbigniew wojna"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1068x778 at 0x265D02658D0>",
    "page_num_int": [
      9,
      12
    ],
    "position_int": [
      [
        9,
        106,
        462,
        679,
        691
      ],
      [
        12,
        128,
        484,
        515,
        527
      ]
    ],
    "top_int": [
      679,
      515
    ],
    "content_with_weight": "6.3English Constituency Parsing\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.",
    "content_ltks": "6 3english constitu pars rethink the incept architectur for comput vision corr ab 1512 00567 2015",
    "content_sm_ltks": "6 3english constitu pars rethink the incept architectur for comput vision corr ab 1512 00567 2015"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x812 at 0x265D0267BE0>",
    "page_num_int": [
      9,
      12
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        12,
        107,
        504,
        545,
        568
      ]
    ],
    "top_int": [
      679,
      545
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. InAdvances in Neural Information Processing Systems, 2015.",
    "content_ltks": "6 3english constitu pars 37 vinyal kaiser koo petrov sutskev and hinton grammar a a foreign languag inadv in neural inform process system 2015",
    "content_sm_ltks": "6 3english constitu pars 37 vinyal kaiser koo petrov sutskev and hinton grammar a a foreign languag inadv in neural inform process system 2015"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1195x874 at 0x265D02641C0>",
    "page_num_int": [
      9,
      12
    ],
    "position_int": [
      [
        9,
        106,
        504,
        679,
        691
      ],
      [
        12,
        106,
        504,
        585,
        628
      ]
    ],
    "top_int": [
      679,
      585
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, WolfgangMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google's neural machinetranslation system: Bridging the gap between human and machine translation. arXiv preprintarXiv:1609.08144,2016.",
    "content_ltks": "6 3english constitu pars 38 yonghui wu mike schuster zhifeng chen quoc v le mohammad norouzi wolfgangmacherey maxim krikun yuan cao qin gao klau macherey et al googl s neural machinetransl system bridg the gap between human and machin translat arxiv preprintarxiv 1609 08144 2016",
    "content_sm_ltks": "6 3english constitu pars 38 yonghui wu mike schuster zhifeng chen quoc v le mohammad norouzi wolfgangmacherey maxim krikun yuan cao qin gao klau macherey et al googl s neural machinetransl system bridg the gap between human and machin translat arxiv preprintarxiv 1609 08144 2016"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1193x810 at 0x265D0264310>",
    "page_num_int": [
      9,
      12
    ],
    "position_int": [
      [
        9,
        106,
        504,
        679,
        691
      ],
      [
        12,
        108,
        505,
        648,
        670
      ]
    ],
    "top_int": [
      679,
      648
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models withfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.",
    "content_ltks": "6 3english constitu pars 39 jie zhou ying cao xuguang wang peng li and wei xu deep recurr model withfast forward connect for neural machin translat corr ab 1606 04199 2016",
    "content_sm_ltks": "6 3english constitu pars 39 jie zhou ying cao xuguang wang peng li and wei xu deep recurr model withfast forward connect for neural machin translat corr ab 1606 04199 2016"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1192x692 at 0x265D0264460>",
    "page_num_int": [
      9,
      12
    ],
    "position_int": [
      [
        9,
        106,
        503,
        679,
        691
      ],
      [
        12,
        107,
        504,
        689,
        722
      ]
    ],
    "top_int": [
      679,
      689
    ],
    "content_with_weight": "6.3English Constituency Parsing\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurateshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume1: Long Papers), pages 434-443. ACL, August 2013.",
    "content_ltks": "6 3english constitu pars 40 muhua zhu yue zhang wenliang chen min zhang and jingbo zhu fast and accurateshift reduc constitu pars in proceed of the 51st annual meet of the acl volume1 long paper page 434 443 acl august 2013",
    "content_sm_ltks": "6 3english constitu pars 40 muhua zhu yue zhang wenliang chen min zhang and jingbo zhu fast and accurateshift reduc constitu pars in proceed of the 51st annual meet of the acl volume1 long paper page 434 443 acl august 2013"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=452x777 at 0x265D02640D0>",
    "page_num_int": [
      9,
      13
    ],
    "position_int": [
      [
        9,
        106,
        257,
        679,
        691
      ],
      [
        13,
        108,
        258,
        72,
        84
      ]
    ],
    "top_int": [
      679,
      72
    ],
    "content_with_weight": "6.3English Constituency Parsing\nAttentionVisualizations",
    "content_ltks": "6 3english constitu pars attentionvisu",
    "content_sm_ltks": "6 3english constitu pars attentionvisu"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x766 at 0x265D0264070>",
    "page_num_int": [
      13,
      13
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        13,
        204,
        228,
        255,
        268
      ]
    ],
    "top_int": [
      153,
      255
    ],
    "content_with_weight": ".S.=\nmaJ",
    "content_ltks": "s maj",
    "content_sm_ltks": "s maj"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x786 at 0x265D02640A0>",
    "page_num_int": [
      13,
      13
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        13,
        228,
        252,
        255,
        274
      ]
    ],
    "top_int": [
      153,
      255
    ],
    "content_with_weight": ".S.=\nAmer",
    "content_ltks": "s amer",
    "content_sm_ltks": "s amer"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x821 at 0x265D02644F0>",
    "page_num_int": [
      13,
      13
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        13,
        236,
        260,
        257,
        288
      ]
    ],
    "top_int": [
      153,
      257
    ],
    "content_with_weight": ".S.=\ngovemm",
    "content_ltks": "s govemm",
    "content_sm_ltks": "s govemm"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1205x865 at 0x265D0264160>",
    "page_num_int": [
      13,
      13
    ],
    "position_int": [
      [
        13,
        128,
        529,
        153,
        160
      ],
      [
        13,
        105,
        507,
        311,
        356
      ]
    ],
    "top_int": [
      153,
      311
    ],
    "content_with_weight": ".S.=\nFigure 3: An example of the attention mechanism following long-distance dependencies in theencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of the verb â€˜making', completing the phrase â€˜making...more difficult'. Attentions here shown only for the word â€˜making'. Different colors represent different heads. Best viewed in color.",
    "content_ltks": "s figur 3 an exampl of the attent mechan follow long distanc depend in theencod self attent in layer 5 of 6 mani of the attent head attend to a distant depend of the verb make complet the phrase make more difficult attent here shown onli for the word make differ color repres differ head best view in color",
    "content_sm_ltks": "s figur 3 an exampl of the attent mechan follow long distanc depend in theencod self attent in layer 5 of 6 mani of the attent head attend to a distant depend of the verb make complet the phrase make more difficult attent here shown onli for the word make differ color repres differ head best view in color"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x815 at 0x265D0264340>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        250,
        274,
        171,
        200
      ]
    ],
    "top_int": [
      153,
      171
    ],
    "content_with_weight": ".S.=\nlication",
    "content_ltks": "s licat",
    "content_sm_ltks": "s licat"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x782 at 0x265D0264400>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        390,
        414,
        181,
        199
      ]
    ],
    "top_int": [
      153,
      181
    ],
    "content_with_weight": ".S.=\nsing",
    "content_ltks": "s sing",
    "content_sm_ltks": "s sing"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x773 at 0x265D0264220>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        193,
        217,
        187,
        201
      ]
    ],
    "top_int": [
      153,
      187
    ],
    "content_with_weight": ".S.=\nfect",
    "content_ltks": "s fect",
    "content_sm_ltks": "s fect"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x786 at 0x265D0264430>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        263,
        287,
        187,
        206
      ]
    ],
    "top_int": [
      153,
      187
    ],
    "content_with_weight": ".S.=\nould",
    "content_ltks": "s ould",
    "content_sm_ltks": "s ould"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x783 at 0x265D0264550>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        250,
        274,
        197,
        215
      ]
    ],
    "top_int": [
      153,
      197
    ],
    "content_with_weight": ".S.=\nappl",
    "content_ltks": "s appl",
    "content_sm_ltks": "s appl"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x773 at 0x265D0264490>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        473,
        497,
        195,
        210
      ]
    ],
    "top_int": [
      153,
      195
    ],
    "content_with_weight": ".S.=\nEO",
    "content_ltks": "seo",
    "content_sm_ltks": "seo"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x761 at 0x265D02642E0>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        321,
        345,
        203,
        213
      ]
    ],
    "top_int": [
      153,
      203
    ],
    "content_with_weight": ".S.=\nthis",
    "content_ltks": "s thi",
    "content_sm_ltks": "s thi"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x759 at 0x265D0264A00>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        363,
        387,
        203,
        213
      ]
    ],
    "top_int": [
      153,
      203
    ],
    "content_with_weight": ".S.=\nwe",
    "content_ltks": "s we",
    "content_sm_ltks": "s we"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x774 at 0x265D0264370>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        124,
        148,
        312,
        327
      ]
    ],
    "top_int": [
      153,
      312
    ],
    "content_with_weight": ".S.=\nThe",
    "content_ltks": "s the",
    "content_sm_ltks": "s the"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x794 at 0x265D0264280>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        168,
        192,
        313,
        335
      ]
    ],
    "top_int": [
      153,
      313
    ],
    "content_with_weight": ".S.=\nnever",
    "content_ltks": "s never",
    "content_sm_ltks": "s never"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x778 at 0x265D0264A90>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        179,
        203,
        312,
        328
      ]
    ],
    "top_int": [
      153,
      312
    ],
    "content_with_weight": ".S.=\nbe",
    "content_ltks": "s be",
    "content_sm_ltks": "s be"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x828 at 0x265D0264190>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        193,
        217,
        310,
        343
      ]
    ],
    "top_int": [
      153,
      310
    ],
    "content_with_weight": ".S.=\n perfect",
    "content_ltks": "s perfect",
    "content_sm_ltks": "s perfect"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x882 at 0x265D02643A0>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        246,
        270,
        310,
        361
      ]
    ],
    "top_int": [
      153,
      310
    ],
    "content_with_weight": ".S.=\napplication",
    "content_ltks": "s applic",
    "content_sm_ltks": "s applic"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x828 at 0x265D0264250>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        263,
        287,
        312,
        345
      ]
    ],
    "top_int": [
      153,
      312
    ],
    "content_with_weight": ".S.=\nshould",
    "content_ltks": "s should",
    "content_sm_ltks": "s should"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x776 at 0x265D02645B0>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        291,
        315,
        312,
        327
      ]
    ],
    "top_int": [
      153,
      312
    ],
    "content_with_weight": ".S.=\njust",
    "content_ltks": "s just",
    "content_sm_ltks": "s just"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x774 at 0x265D0264730>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        319,
        343,
        312,
        327
      ]
    ],
    "top_int": [
      153,
      312
    ],
    "content_with_weight": ".S.=\nthis",
    "content_ltks": "s thi",
    "content_sm_ltks": "s thi"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x798 at 0x265D0265750>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        346,
        370,
        310,
        333
      ]
    ],
    "top_int": [
      153,
      310
    ],
    "content_with_weight": ".S.=\nwhat",
    "content_ltks": "s what",
    "content_sm_ltks": "s what"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x833 at 0x265D0264760>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        389,
        413,
        311,
        345
      ]
    ],
    "top_int": [
      153,
      311
    ],
    "content_with_weight": ".S.=\nmissing",
    "content_ltks": "s miss",
    "content_sm_ltks": "s miss"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x821 at 0x265D0264850>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        446,
        470,
        312,
        343
      ]
    ],
    "top_int": [
      153,
      312
    ],
    "content_with_weight": ".S.=\nopinion",
    "content_ltks": "s opinion",
    "content_sm_ltks": "s opinion"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x811 at 0x265D02644C0>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        472,
        496,
        312,
        340
      ]
    ],
    "top_int": [
      153,
      312
    ],
    "content_with_weight": ".S.=\n<EOS>",
    "content_ltks": "seo",
    "content_sm_ltks": "seo"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x795 at 0x265D0264910>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        487,
        511,
        314,
        336
      ]
    ],
    "top_int": [
      153,
      314
    ],
    "content_with_weight": ".S.=\n<pad>",
    "content_ltks": "s pad",
    "content_sm_ltks": "s pad"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=81x882 at 0x265D0264A60>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        155,
        153,
        160
      ],
      [
        14,
        247,
        274,
        381,
        432
      ]
    ],
    "top_int": [
      153,
      381
    ],
    "content_with_weight": ".S.=\napplicationshould ",
    "content_ltks": "s applicationshould",
    "content_sm_ltks": "s applicationshould"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=72x778 at 0x265D0264FD0>",
    "page_num_int": [
      13,
      14
    ],
    "position_int": [
      [
        13,
        128,
        152,
        153,
        160
      ],
      [
        14,
        393,
        417,
        401,
        417
      ]
    ],
    "top_int": [
      153,
      401
    ],
    "content_with_weight": ".S.=\nsing",
    "content_ltks": "s sing",
    "content_sm_ltks": "s sing"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=25x767 at 0x265D0265030>",
    "page_num_int": [
      14,
      14
    ],
    "position_int": [
      [
        14,
        449,
        457,
        406,
        415
      ],
      [
        14,
        490,
        498,
        409,
        419
      ]
    ],
    "top_int": [
      406,
      409
    ],
    "content_with_weight": ".0\npe",
    "content_ltks": "0 pe",
    "content_sm_ltks": "0 pe"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=124x782 at 0x265D0264AC0>",
    "page_num_int": [
      14,
      14
    ],
    "position_int": [
      [
        14,
        449,
        490,
        406,
        415
      ],
      [
        14,
        122,
        164,
        416,
        431
      ]
    ],
    "top_int": [
      406,
      416
    ],
    "content_with_weight": ".0\nMMM",
    "content_ltks": "0 mmm",
    "content_sm_ltks": "0 mmm"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=28x786 at 0x265D0264C10>",
    "page_num_int": [
      14,
      14
    ],
    "position_int": [
      [
        14,
        449,
        458,
        406,
        415
      ],
      [
        14,
        126,
        135,
        529,
        546
      ]
    ],
    "top_int": [
      406,
      529
    ],
    "content_with_weight": ".0\nThe",
    "content_ltks": "0 the",
    "content_sm_ltks": "0 the"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=27x797 at 0x265D02646A0>",
    "page_num_int": [
      14,
      14
    ],
    "position_int": [
      [
        14,
        449,
        458,
        406,
        415
      ],
      [
        14,
        139,
        148,
        530,
        551
      ]
    ],
    "top_int": [
      406,
      530
    ],
    "content_with_weight": ".0\nLaw",
    "content_ltks": "0 law",
    "content_sm_ltks": "0 law"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x794 at 0x265D0264C40>",
    "page_num_int": [
      14,
      14
    ],
    "position_int": [
      [
        14,
        449,
        459,
        406,
        415
      ],
      [
        14,
        151,
        161,
        529,
        549
      ]
    ],
    "top_int": [
      406,
      529
    ],
    "content_with_weight": ".0\nwill",
    "content_ltks": "0 will",
    "content_sm_ltks": "0 will"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=28x812 at 0x265D0264C70>",
    "page_num_int": [
      14,
      14
    ],
    "position_int": [
      [
        14,
        449,
        458,
        406,
        415
      ],
      [
        14,
        167,
        176,
        530,
        556
      ]
    ],
    "top_int": [
      406,
      530
    ],
    "content_with_weight": ".0\nnever",
    "content_ltks": "0 never",
    "content_sm_ltks": "0 never"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=37x830 at 0x265D0264DC0>",
    "page_num_int": [
      14,
      14
    ],
    "position_int": [
      [
        14,
        449,
        461,
        406,
        415
      ],
      [
        14,
        192,
        204,
        528,
        560
      ]
    ],
    "top_int": [
      406,
      528
    ],
    "content_with_weight": ".0\nperfect",
    "content_ltks": "0 perfect",
    "content_sm_ltks": "0 perfect"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=77x839 at 0x265D0264D60>",
    "page_num_int": [
      14,
      14
    ],
    "position_int": [
      [
        14,
        449,
        474,
        406,
        415
      ],
      [
        14,
        248,
        274,
        527,
        561
      ]
    ],
    "top_int": [
      406,
      527
    ],
    "content_with_weight": ".0\napplicationshould",
    "content_ltks": "0 applicationshould",
    "content_sm_ltks": "0 applicationshould"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=37x804 at 0x265D0264DF0>",
    "page_num_int": [
      14,
      14
    ],
    "position_int": [
      [
        14,
        336,
        349,
        531,
        540
      ],
      [
        14,
        349,
        361,
        529,
        552
      ]
    ],
    "top_int": [
      531,
      529
    ],
    "content_with_weight": ".S\nwhat",
    "content_ltks": "s what",
    "content_sm_ltks": "s what"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=35x841 at 0x265D0264E20>",
    "page_num_int": [
      14,
      14
    ],
    "position_int": [
      [
        14,
        336,
        348,
        531,
        540
      ],
      [
        14,
        391,
        403,
        529,
        565
      ]
    ],
    "top_int": [
      531,
      529
    ],
    "content_with_weight": ".S\n missing",
    "content_ltks": "s miss",
    "content_sm_ltks": "s miss"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=34x833 at 0x265D0264F10>",
    "page_num_int": [
      14,
      14
    ],
    "position_int": [
      [
        14,
        420,
        432,
        531,
        539
      ],
      [
        14,
        446,
        457,
        529,
        563
      ]
    ],
    "top_int": [
      531,
      529
    ],
    "content_with_weight": ".n\nopinion",
    "content_ltks": "n opinion",
    "content_sm_ltks": "n opinion"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=37x825 at 0x265D0264F70>",
    "page_num_int": [
      14,
      14
    ],
    "position_int": [
      [
        14,
        420,
        433,
        531,
        539
      ],
      [
        14,
        475,
        488,
        530,
        561
      ]
    ],
    "top_int": [
      531,
      530
    ],
    "content_with_weight": ".n\n<EOS>",
    "content_ltks": "n eo",
    "content_sm_ltks": "n eo"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x811 at 0x265D0264FA0>",
    "page_num_int": [
      14,
      14
    ],
    "position_int": [
      [
        14,
        420,
        430,
        531,
        539
      ],
      [
        14,
        490,
        500,
        532,
        558
      ]
    ],
    "top_int": [
      531,
      532
    ],
    "content_with_weight": ".n\n<pad>",
    "content_ltks": "n pad",
    "content_sm_ltks": "n pad"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x832 at 0x265D0265060>",
    "page_num_int": [
      14,
      14
    ],
    "position_int": [
      [
        14,
        420,
        820,
        531,
        539
      ],
      [
        14,
        105,
        505,
        613,
        646
      ]
    ],
    "top_int": [
      531,
      613
    ],
    "content_with_weight": ".n\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:Full attentions for head 5. Bottom: Isolated attentions from just the word â€œitsâ€² for attention heads 5 and 6. Note that the attentions are very sharp for this word.",
    "content_ltks": "n figur 4 two attent head also in layer 5 of 6 appar involv in anaphora resolut top full attent for head 5 bottom isol attent from just the word it for attent head 5 and 6 note that the attent are veri sharp for thi word",
    "content_sm_ltks": "n figur 4 two attent head also in layer 5 of 6 appar involv in anaphora resolut top full attent for head 5 bottom isol attent from just the word it for attent head 5 and 6 note that the attent are veri sharp for thi word"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=28x837 at 0x265D0265090>",
    "page_num_int": [
      14,
      15
    ],
    "position_int": [
      [
        14,
        420,
        430,
        531,
        539
      ],
      [
        15,
        247,
        257,
        185,
        219
      ]
    ],
    "top_int": [
      531,
      185
    ],
    "content_with_weight": ".n\nplication",
    "content_ltks": "n plicat",
    "content_sm_ltks": "n plicat"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=28x763 at 0x265D0265210>",
    "page_num_int": [
      14,
      15
    ],
    "position_int": [
      [
        14,
        420,
        430,
        531,
        539
      ],
      [
        15,
        194,
        204,
        203,
        213
      ]
    ],
    "top_int": [
      531,
      203
    ],
    "content_with_weight": ".n\nec",
    "content_ltks": "n ec",
    "content_sm_ltks": "n ec"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=28x810 at 0x265D0264BB0>",
    "page_num_int": [
      14,
      15
    ],
    "position_int": [
      [
        14,
        420,
        430,
        531,
        539
      ],
      [
        15,
        262,
        272,
        202,
        227
      ]
    ],
    "top_int": [
      531,
      202
    ],
    "content_with_weight": ".n\nshould",
    "content_ltks": "n should",
    "content_sm_ltks": "n should"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=28x765 at 0x265D0265270>",
    "page_num_int": [
      14,
      15
    ],
    "position_int": [
      [
        14,
        420,
        430,
        531,
        539
      ],
      [
        15,
        193,
        203,
        328,
        339
      ]
    ],
    "top_int": [
      531,
      328
    ],
    "content_with_weight": ".n\nect",
    "content_ltks": "n ect",
    "content_sm_ltks": "n ect"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=69x828 at 0x265D0265540>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        233,
        256,
        327,
        338
      ],
      [
        15,
        248,
        271,
        328,
        357
      ]
    ],
    "top_int": [
      327,
      328
    ],
    "content_with_weight": ".S\napplicationpinous",
    "content_ltks": "s applicationpin",
    "content_sm_ltks": "s applicationpin"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x782 at 0x265D0265450>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        346,
        356,
        327,
        345
      ]
    ],
    "top_int": [
      328,
      327
    ],
    "content_with_weight": ".s\nwhat",
    "content_ltks": "s what",
    "content_sm_ltks": "s what"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x763 at 0x265D02654B0>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        390,
        400,
        328,
        340
      ]
    ],
    "top_int": [
      328,
      328
    ],
    "content_with_weight": ".s\ning",
    "content_ltks": "s ing",
    "content_sm_ltks": "s ing"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x783 at 0x265D0265480>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        193,
        203,
        337,
        355
      ]
    ],
    "top_int": [
      328,
      337
    ],
    "content_with_weight": ".s\nperfe",
    "content_ltks": "s perf",
    "content_sm_ltks": "s perf"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x793 at 0x265D0265420>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        390,
        400,
        337,
        359
      ]
    ],
    "top_int": [
      328,
      337
    ],
    "content_with_weight": ".s\nmissi",
    "content_ltks": "s missi",
    "content_sm_ltks": "s missi"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x773 at 0x265D0265390>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        473,
        483,
        337,
        352
      ]
    ],
    "top_int": [
      328,
      337
    ],
    "content_with_weight": ".s\nEO",
    "content_ltks": "seo",
    "content_sm_ltks": "seo"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x767 at 0x265D02653F0>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        447,
        457,
        341,
        354
      ]
    ],
    "top_int": [
      328,
      341
    ],
    "content_with_weight": ".s\nopir",
    "content_ltks": "s opir",
    "content_sm_ltks": "s opir"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x824 at 0x265D02653C0>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        251,
        261,
        404,
        436
      ]
    ],
    "top_int": [
      328,
      404
    ],
    "content_with_weight": ".s\nolication",
    "content_ltks": "s olic",
    "content_sm_ltks": "s olic"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x810 at 0x265D02654E0>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        193,
        203,
        420,
        448
      ]
    ],
    "top_int": [
      328,
      420
    ],
    "content_with_weight": ".s\nperfect",
    "content_ltks": "s perfect",
    "content_sm_ltks": "s perfect"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x807 at 0x265D02652D0>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        263,
        273,
        420,
        446
      ]
    ],
    "top_int": [
      328,
      420
    ],
    "content_with_weight": ".s\nshould",
    "content_ltks": "s should",
    "content_sm_ltks": "s should"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x807 at 0x265D0265330>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        390,
        400,
        418,
        444
      ]
    ],
    "top_int": [
      328,
      418
    ],
    "content_with_weight": ".s\nnissind",
    "content_ltks": "s nissind",
    "content_sm_ltks": "s nissind"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x758 at 0x265D0265300>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        124,
        134,
        434,
        444
      ]
    ],
    "top_int": [
      328,
      434
    ],
    "content_with_weight": ".s\nhe",
    "content_ltks": "s he",
    "content_sm_ltks": "s he"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x758 at 0x265D02652A0>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        152,
        162,
        436,
        446
      ]
    ],
    "top_int": [
      328,
      436
    ],
    "content_with_weight": ".s\nWill",
    "content_ltks": "s will",
    "content_sm_ltks": "s will"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x755 at 0x265D0265690>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        251,
        261,
        435,
        444
      ]
    ],
    "top_int": [
      328,
      435
    ],
    "content_with_weight": ".s\napp",
    "content_ltks": "s app",
    "content_sm_ltks": "s app"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x760 at 0x265D0265360>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        376,
        386,
        435,
        446
      ]
    ],
    "top_int": [
      328,
      435
    ],
    "content_with_weight": ".s\nare",
    "content_ltks": "s are",
    "content_sm_ltks": "s are"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x758 at 0x265D0265240>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        124,
        134,
        547,
        557
      ]
    ],
    "top_int": [
      328,
      547
    ],
    "content_with_weight": ".s\nhe",
    "content_ltks": "s he",
    "content_sm_ltks": "s he"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x770 at 0x265D02651E0>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        165,
        175,
        543,
        557
      ]
    ],
    "top_int": [
      328,
      543
    ],
    "content_with_weight": ".s\nver",
    "content_ltks": "s ver",
    "content_sm_ltks": "s ver"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x821 at 0x265D0265150>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        192,
        202,
        543,
        574
      ]
    ],
    "top_int": [
      328,
      543
    ],
    "content_with_weight": ".s\nperfect",
    "content_ltks": "s perfect",
    "content_sm_ltks": "s perfect"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x773 at 0x265D0265720>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        332,
        342,
        328,
        335
      ],
      [
        15,
        220,
        230,
        543,
        558
      ]
    ],
    "top_int": [
      328,
      543
    ],
    "content_with_weight": ".s\nbut",
    "content_ltks": "s but",
    "content_sm_ltks": "s but"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=35x891 at 0x265D0265180>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        234,
        245,
        543,
        556
      ],
      [
        15,
        248,
        260,
        544,
        593
      ]
    ],
    "top_int": [
      543,
      544
    ],
    "content_with_weight": ".$\napplication",
    "content_ltks": "applic",
    "content_sm_ltks": "applic"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=35x836 at 0x265D0265120>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        234,
        246,
        543,
        556
      ],
      [
        15,
        262,
        273,
        544,
        575
      ]
    ],
    "top_int": [
      543,
      544
    ],
    "content_with_weight": ".$\npInous",
    "content_ltks": "pinou",
    "content_sm_ltks": "pinou"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x778 at 0x265D02650C0>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        234,
        244,
        543,
        556
      ],
      [
        15,
        320,
        330,
        547,
        558
      ]
    ],
    "top_int": [
      543,
      547
    ],
    "content_with_weight": ".$\nthis",
    "content_ltks": "thi",
    "content_sm_ltks": "thi"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x778 at 0x265D02651B0>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        234,
        244,
        543,
        556
      ],
      [
        15,
        362,
        372,
        546,
        557
      ]
    ],
    "top_int": [
      543,
      546
    ],
    "content_with_weight": ".$\nwe",
    "content_ltks": "we",
    "content_sm_ltks": "we"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x782 at 0x265D02655A0>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        234,
        244,
        543,
        556
      ],
      [
        15,
        376,
        386,
        545,
        557
      ]
    ],
    "top_int": [
      543,
      545
    ],
    "content_with_weight": ".$\nare",
    "content_ltks": "are",
    "content_sm_ltks": "are"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x780 at 0x265D02648E0>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        234,
        244,
        543,
        556
      ],
      [
        15,
        390,
        400,
        546,
        557
      ]
    ],
    "top_int": [
      543,
      546
    ],
    "content_with_weight": ".$\ning",
    "content_ltks": "ing",
    "content_sm_ltks": "ing"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x782 at 0x265D0265510>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        234,
        244,
        543,
        556
      ],
      [
        15,
        166,
        176,
        556,
        568
      ]
    ],
    "top_int": [
      543,
      556
    ],
    "content_with_weight": ".$\nney",
    "content_ltks": "ney",
    "content_sm_ltks": "ney"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x811 at 0x265D02656F0>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        234,
        244,
        543,
        556
      ],
      [
        15,
        390,
        400,
        555,
        577
      ]
    ],
    "top_int": [
      543,
      555
    ],
    "content_with_weight": ".$\nmissi",
    "content_ltks": "missi",
    "content_sm_ltks": "missi"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=30x785 at 0x265D02658A0>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        234,
        244,
        543,
        556
      ],
      [
        15,
        447,
        457,
        559,
        572
      ]
    ],
    "top_int": [
      543,
      559
    ],
    "content_with_weight": ".$\nopir",
    "content_ltks": "opir",
    "content_sm_ltks": "opir"
  },
  {
    "docnm_kwd": "6d1baae7-eee7-476c-8ad8-33b10ea05f4b.pdf",
    "title_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "title_sm_tks": "6d1baae7 eee7 476c 8ad8 33b10ea05f4b",
    "image": "<PIL.Image.Image image mode=RGB size=1200x844 at 0x265D0278070>",
    "page_num_int": [
      15,
      15
    ],
    "position_int": [
      [
        15,
        234,
        634,
        543,
        556
      ],
      [
        15,
        105,
        505,
        601,
        634
      ]
    ],
    "top_int": [
      543,
      601
    ],
    "content_with_weight": ".$\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the sentence. We give two such examples above, from two different heads from the encoder self-attentionat layer 5 of 6. The heads clearly learned to perform different tasks.",
    "content_ltks": "figur 5 mani of the attent head exhibit behaviour that seem relat to the structur of the sentenc we give two such exampl abov from two differ head from the encod self attentionat layer 5 of 6 the head clearli learn to perform differ task",
    "content_sm_ltks": "figur 5 mani of the attent head exhibit behaviour that seem relat to the structur of the sentenc we give two such exampl abov from two differ head from the encod self attentionat layer 5 of 6 the head clearli learn to perform differ task"
  }
]